{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader# For custom data-sets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "n_class = 27\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "    'name'        , \n",
    "    'level3Id'    , \n",
    "    'color'       , \n",
    "    ] )\n",
    "\n",
    "labels = [\n",
    "    #       name                     level3Id  color\n",
    "    Label(  'road'                 ,    0  , (128, 64,128)  ),\n",
    "    Label(  'drivable fallback'    ,    1  , ( 81,  0, 81)  ),\n",
    "    Label(  'sidewalk'             ,    2  , (244, 35,232)  ),\n",
    "    Label(  'non-drivable fallback',    3  , (152,251,152)  ),\n",
    "    Label(  'person/animal'        ,    4  , (220, 20, 60)  ),\n",
    "    Label(  'rider'                ,    5  , (255,  0,  0)  ),\n",
    "    Label(  'motorcycle'           ,    6  , (  0,  0,230)  ),\n",
    "    Label(  'bicycle'              ,   7  , (119, 11, 32)  ),\n",
    "    Label(  'autorickshaw'         ,   8  , (255, 204, 54) ),\n",
    "    Label(  'car'                  ,   9  , (  0,  0,142)  ),\n",
    "    Label(  'truck'                ,  10 ,  (  0,  0, 70)  ),\n",
    "    Label(  'bus'                  ,  11 ,  (  0, 60,100)  ),\n",
    "    Label(  'vehicle fallback'     ,  12 ,  (136, 143, 153)),  \n",
    "    Label(  'curb'                 ,   13 ,  (220, 190, 40)),\n",
    "    Label(  'wall'                 ,  14 ,  (102,102,156)  ),\n",
    "    Label(  'fence'                ,  15 ,  (190,153,153)  ),\n",
    "    Label(  'guard rail'           ,  16 ,  (180,165,180)  ),\n",
    "    Label(  'billboard'            ,   17 ,  (174, 64, 67) ),\n",
    "    Label(  'traffic sign'         ,  18 ,  (220,220,  0)  ),\n",
    "    Label(  'traffic light'        ,  19 ,  (250,170, 30)  ),\n",
    "    Label(  'pole'                 ,  20 ,  (153,153,153)  ),\n",
    "    Label(  'obs-str-bar-fallback' , 21 ,  (169, 187, 214) ),  \n",
    "    Label(  'building'             ,  22 ,  ( 70, 70, 70)  ),\n",
    "    Label(  'bridge/tunnel'        ,  23 ,  (150,100,100)  ),\n",
    "    Label(  'vegetation'           ,  24 ,  (107,142, 35)  ),\n",
    "    Label(  'sky'                  ,  25 ,  ( 70,130,180)  ),\n",
    "    Label(  'unlabeled'            ,  26 ,  (  0,  0,  0)  ),\n",
    "]   \n",
    "\n",
    "class IddDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, n_class=n_class, transforms_=None):\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.n_class   = n_class\n",
    "        self.mode = csv_file\n",
    "        self.do_transform = False\n",
    "        \n",
    "        #For 4a\n",
    "        if transforms_==True: #Augmenting the training dataset. Should be \"True\" only when we call train_dataloader.\n",
    "            frames = [self.data,self.data]\n",
    "            result = pd.concat(frames)\n",
    "            self.data = result\n",
    "            self.do_transform = True \n",
    "        \n",
    "        # Add any transformations here\n",
    "        self.resize_transform = transforms.Resize((256, 256))\n",
    "        # The following transformation normalizes each channel using the mean and std provided\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 0]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        label_name = self.data.iloc[idx, 1]\n",
    "        label = Image.open(label_name)\n",
    "        #print(\"Img type is {}\".format(type(img)))\n",
    "        \n",
    "        #do any one transformation randomly, \n",
    "        if self.do_transform:\n",
    "            #print(\"Applying transformation...\")\n",
    "           #there will be 2 copies of each image. \n",
    "            # So each copy will be transformed randomly.\n",
    "            transform_type = random.randint(0,2)\n",
    "            \n",
    "            if transform_type==0:\n",
    "                #using mirror flip\n",
    "                img = transforms.functional.hflip(img)\n",
    "                label = transforms.functional.hflip(label)\n",
    "\n",
    "            elif transform_type==1:\n",
    "                #rotating the image \n",
    "                rotate_transform = transforms.RandomRotation(30) \n",
    "                img = rotate_transform(img)\n",
    "                label = rotate_transform(label)\n",
    "\n",
    "            else:\n",
    "                #different crops \n",
    "                #self.resize_transform = transforms.RandomResizedCrop(((256,256))) \n",
    "                crop_transform = transforms.RandomCrop(((256,512))) \n",
    "                img = crop_transform(img)\n",
    "                label = crop_transform(label)\n",
    "                \n",
    "        #resize your input images such that its dimensions are a power of 2\n",
    "        img = self.resize_transform(img)\n",
    "        label = self.resize_transform(label)\n",
    "        \n",
    "        img = np.asarray(img) / 255. # scaling [0-255] values to [0-1]\n",
    "        label = np.asarray(label)\n",
    "        # Normalization\n",
    "        img = self.transforms(img).float()\n",
    "        # Convert to tensor\n",
    "        label = torch.from_numpy(label.copy()).long()\n",
    "\n",
    "        # create one-hot encoding\n",
    "        h, w = label.shape\n",
    "        target = torch.zeros(self.n_class, h, w)\n",
    "        for c in range(self.n_class):\n",
    "            target[c][label == c] = 1\n",
    "        return img, target, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IddDataset(csv_file='train.csv',transforms_=True)\n",
    "val_dataset = IddDataset(csv_file='val.csv')\n",
    "test_dataset = IddDataset(csv_file='test.csv')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 3, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 3, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 3, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8036 2679\n",
      "2009\n",
      "1004\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),train_loader.__len__())\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5614cf2890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Print the shape of the training dataset\n",
    "#print(train_dataset[0][0].shape)\n",
    "# Permute the object into a different shape\n",
    "idx = 0\n",
    "train_image = train_dataset.__getitem__(idx)\n",
    "print(type(train_image[idx]),train_image[idx].shape)\n",
    "tensor_image = train_image[idx]\n",
    "# print(type(tensor_image), tensor_image.shape)\n",
    "plt.imshow(tensor_image.permute(1, 2, 0))\n",
    "# plt.imshow(test_image.permute(1, 2, 0))\n",
    "# plt.imshow(val_image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_coefficient_loss(torch.nn.Module):\n",
    "    def init(self):\n",
    "        super(dice_coefficient_loss, self).init()\n",
    "        \n",
    "    def forward(self,pred, target):\n",
    "        # skip the batch and class axis for calculating Dice score (bxcx......)\n",
    "        axes = tuple(range(2, len(pred.shape))) \n",
    "        #we can approximate |A∩B| as the element-wise multiplication between the prediction and target, and then sum the resulting matrix.\n",
    "        #common activations between our prediction and target\n",
    "        numerator = 2 * torch.sum(pred * target,axes) \n",
    "        #quantity of activations in pred & target separately\n",
    "        denominator = torch.sum((pred*pred) + (target*target),axes)\n",
    "        #formulate a loss function which can be minimized, we'll simply use 1−Dice, same effect as normalizing loss\n",
    "        return 1 - torch.mean((numerator + 1e-6) / (denominator + 1e-6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size =  8036\n",
      "No of classes =  27\n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "#from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "\n",
    "# First read the dataset\n",
    "train_dataset = IddDataset(csv_file='train.csv',transforms_=True)\n",
    "val_dataset = IddDataset(csv_file='val.csv')\n",
    "test_dataset = IddDataset(csv_file='test.csv')\n",
    "\n",
    "# train_loader, val_loader and test_loader are three different sets of data\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 6, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 6, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 6, num_workers=4, shuffle=False)\n",
    "\n",
    "print(\"Train dataset size = \",len(train_dataset))\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        #torch.nn.init.xavier_uniform(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        #print(\"Dimension of weight = {}\".format(m.weight.shape))\n",
    "        #print(\"Dimension of bias = {}\".format(m.bias.shape))\n",
    "        #torch.nn.init.xavier_uniform(m.bias.data)\n",
    "        torch.nn.init.zeros_(m.bias.data)\n",
    "\n",
    "        \n",
    "        \n",
    "MODEL_NAME = 'best_model_4a'        \n",
    "epochs = 100      \n",
    "criterion = dice_coefficient_loss()\n",
    "#nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "fcn_model = FCN(n_class=n_class)\n",
    "print(\"No of classes = \",n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(fcn_model.parameters(), lr=5e-3)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using GPU\")\n",
    "    fcn_model = fcn_model.cuda()\n",
    "\n",
    "        \n",
    "def train():\n",
    "    print(\"Reached train function\")\n",
    "    best_loss = float('inf')\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss_batch = []\n",
    "        ts = time.time()\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        for itera, (X, tar, Y) in enumerate(train_loader):\n",
    "            #print(\"Printing the contents of X, tar and Y\")\n",
    "            #print(\"X, tar, Y are {}, {} and {}\".format(type(X), type(tar), type(Y)))\n",
    "            optimizer.zero_grad()\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()# Move your inputs onto the gpu\n",
    "                #labels = tar.long()\n",
    "                train_labels = Y.cuda()# Move your labels onto the gpu\n",
    "                train_targets = tar.cuda()\n",
    "            else:\n",
    "                inputs, train_labels,train_targets = X, Y,tar # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = fcn_model(inputs)\n",
    "            #loss = criterion(outputs, train_labels)\n",
    "            predictions = F.softmax(outputs,1)\n",
    "            loss = criterion(predictions,train_targets)\n",
    "            loss = torch.unsqueeze(loss,0)\n",
    "            loss = loss.mean()\n",
    "            train_loss_batch.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if itera % 100 == 0:\n",
    "                print(\"TRAINING: epoch{}, iter{}, loss: {}\".format(epoch, itera, loss.item())) \n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        train_loss.append(np.mean(np.array(train_loss_batch)))\n",
    "        curr_val_loss, val_inputs = val(epoch)\n",
    "        val_loss.append(curr_val_loss)\n",
    "        if curr_val_loss<best_loss:\n",
    "            print (\"Saving best model after %d epochs.\" % (epoch))\n",
    "            best_loss = curr_val_loss\n",
    "            torch.save(fcn_model, MODEL_NAME)\n",
    "        if epoch>=5:\n",
    "            stop = 0\n",
    "            for i in range(0,5):\n",
    "                if val_loss[epoch-i] > val_loss[epoch-i-1]:\n",
    "                    stop = stop + 1\n",
    "            if stop == 5 :\n",
    "                print (\"EarlyStop after %d epochs.\" % (epoch))\n",
    "                return train_loss, val_loss, val_inputs\n",
    "        torch.save(fcn_model, 'last_saved_model')\n",
    "        fcn_model.train()\n",
    "    return train_loss, val_loss, val_inputs\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    fcn_model.eval() # Don't forget to put in eval mode !\n",
    "    val_loss = []\n",
    "    val_iou = []\n",
    "    val_acc = []\n",
    "    with torch.no_grad():\n",
    "        for itera, (X, tar, Y) in enumerate(val_loader):\n",
    "            #print(\"Printing the contents of X, tar and Y\")\n",
    "            #print(\"X, tar, Y are {}, {} and {}\".format(type(X), type(tar), type(Y)))\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()# Move your inputs onto the gpu\n",
    "                #labels= tar.long()\n",
    "                val_labels = Y.cuda()# Move your labels onto the gpu\n",
    "                val_targets = tar.cuda()\n",
    "            else:\n",
    "                inputs, val_labels,val_targets = X, Y,tar#.long()# Unpack variables into inputs and labels\n",
    "            outputs = fcn_model(inputs)\n",
    "            #loss = criterion(outputs, val_labels)\n",
    "            predictions = F.softmax(outputs,1)\n",
    "            loss = criterion(predictions,val_targets)\n",
    "            loss = torch.unsqueeze(loss,0)\n",
    "            loss = loss.mean()\n",
    "            val_loss.append(loss.item())\n",
    "            if itera % 100 == 0:\n",
    "                print(\"VALIDATION: iter{}, loss: {}\".format(itera, loss.item()))\n",
    "            #predictions = F.softmax(outputs,1)\n",
    "            predictions = torch.argmax(predictions,dim=1)\n",
    "            #print(\"Preds shape = \",predictions.shape) #[2, 256, 256]\n",
    "            #print(\"Shape of Y = \",Y.shape) #[2, 256, 256]\n",
    "            iou_row,avg_iou = iou(predictions,val_labels)\n",
    "            val_iou.append(avg_iou)\n",
    "            #print(\"Val acc = \",pixel_acc(predictions,Y))\n",
    "            val_acc.append(pixel_acc(predictions,val_labels))\n",
    "            #TODO: pass pred_one_hot,labels_one_hot for accuracy and iou calculations\n",
    "        #print(\"Last itera's inputs size: \",len(inputs))\n",
    "        #print(\"Last itera's target size: \",len(Y))\n",
    "        #print(\"Last itera's prediction: \", predictions)\n",
    "        #print(\"Last itera's accuracy: \",pixel_acc(predictions,Y))\n",
    "#         val_loss = val_loss[:-1]\n",
    "#         val_iou = val_iou[:-1]\n",
    "#         val_acc = val_acc[:-1]\n",
    "        avg_loss = np.mean(np.asarray(val_loss))\n",
    "        avg_iou = np.mean(np.asarray(val_iou))\n",
    "        avg_acc = np.mean(np.asarray(val_acc))\n",
    "        print(\"Validation epoch {}: avg_iou = {}, avg_acc = {}\".format(epoch,avg_iou,avg_acc))\n",
    "        return avg_loss, inputs    \n",
    "    \n",
    "def test():\n",
    "    fcn_model = torch.load(MODEL_NAME)\n",
    "    fcn_model.eval()\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    val_iou = []\n",
    "    val_acc = []\n",
    "    val_ious_cls = []\n",
    "    with torch.no_grad():\n",
    "        for itera, (X, tar, Y) in enumerate(val_loader):\n",
    "            #print(\"Printing the contents of X, tar and Y\")\n",
    "            #print(\"X, tar, Y are {}, {} and {}\".format(type(X), type(tar), type(Y)))\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()# Move your inputs onto the gpu\n",
    "                #labels= tar.long()\n",
    "                test_labels = Y.cuda()# Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, test_labels = X,Y#.long()# Unpack variables into inputs and labels\n",
    "            outputs = fcn_model(inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs,1)\n",
    "            # create one-hot encoding\n",
    "            predictions = torch.argmax(predictions,dim=1)\n",
    "            #print(\"Preds shape = \",predictions.shape) #[2, 256, 256]\n",
    "            #print(\"Shape of Y = \",Y.shape) #[2, 256, 256]\n",
    "            iou_row,avg_iou = iou(predictions,test_labels)\n",
    "            if iou_row is not None:\n",
    "                #iou_row = (iou_row).cpu().numpy()\n",
    "                val_ious_cls.append(iou_row)\n",
    "            val_iou.append(avg_iou)\n",
    "            val_acc.append(pixel_acc(predictions,test_labels))\n",
    "        #val_loss = val_loss[:-1]\n",
    "#         val_iou = val_iou[:-1]\n",
    "#         val_acc = val_acc[:-1]\n",
    "        avg_iou = np.mean(np.asarray(val_iou))\n",
    "        avg_acc = np.mean(np.asarray(val_acc))\n",
    "        if iou_row is not None:\n",
    "            avg_ious_cls = np.nanmean(np.asarray(val_ious_cls),axis=0) #iou for the class when it's union=0 will be nan\n",
    "        print(\"Final test from best model : avg_iou = {}, avg_acc = {}\".format(avg_iou,avg_acc))\n",
    "        print(\" Class wise ious getting saved in \"+MODEL_NAME+\"_IOU_Classwise.csv file\")\n",
    "        \n",
    "        if iou_row is not None:\n",
    "            d = []\n",
    "            labels_len = len(labels)\n",
    "            for idx in range(0,labels_len-1):\n",
    "                 d.append((labels[idx].name, avg_ious_cls[labels[idx].level3Id]))\n",
    "            df = pd.DataFrame(d, columns=('Label name', 'IoU'))\n",
    "            df.to_csv(MODEL_NAME+\"_IOU_Classwise.csv\", sep='\\t')\n",
    "\n",
    "            test_loader = DataLoader(dataset=test_dataset, batch_size= 1, num_workers=4, shuffle=False)\n",
    "            for itera, (X, tar, Y) in enumerate(test_loader):\n",
    "                if use_gpu:\n",
    "                    inputs = X.cuda()# Move your inputs onto the gpu\n",
    "                    test_labels = Y.cuda()# Move your labels onto the gpu\n",
    "                else:\n",
    "                    inputs, test_labels = X, Y#.long() # Unpack variables into inputs and labels\n",
    "                outputs = fcn_model(inputs)\n",
    "                predictions = torch.nn.functional.softmax(outputs,1)\n",
    "                predictions = torch.argmax(predictions,dim=1)\n",
    "                break\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            inputImage = inputs[0].permute(1, 2, 0).cpu().numpy()\n",
    "            plt.imshow(inputImage, cmap='gray')\n",
    "            plt.show()\n",
    "            rows, cols = predictions.shape[1], predictions.shape[2]\n",
    "            #print(labels)\n",
    "            new_predictions = np.zeros((predictions.shape[1], predictions.shape[2], 3))\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    idx = int(predictions[0][row][col])\n",
    "                    new_predictions[row][col][:] = np.asarray(labels[idx].color)       \n",
    "\n",
    "            plt.imshow(inputImage, cmap='gray')\n",
    "            plt.imshow(new_predictions, cmap='jet', alpha=0.5)\n",
    "            fig_name = MODEL_NAME+\"_Overlayed.jpg\"  \n",
    "            plt.savefig(fig_name)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_loss,val_loss):\n",
    "    title = \"Loss \"\n",
    "    fig_name = MODEL_NAME+\"_loss.jpg\"\n",
    "    x = [i for i in range(len(train_loss))]\n",
    "    plt.plot(x, train_loss,label=\"Train Loss\")\n",
    "    plt.plot(x, val_loss,label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"# of epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.savefig(fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached train function\n",
      "Epoch: 0\n",
      "TRAINING: epoch0, iter0, loss: 0.9633728265762329\n",
      "TRAINING: epoch0, iter100, loss: 0.9240798950195312\n",
      "TRAINING: epoch0, iter200, loss: 0.927945613861084\n",
      "TRAINING: epoch0, iter300, loss: 0.9300602674484253\n",
      "TRAINING: epoch0, iter400, loss: 0.8755654096603394\n",
      "TRAINING: epoch0, iter500, loss: 0.8991370797157288\n",
      "TRAINING: epoch0, iter600, loss: 0.9463097453117371\n",
      "TRAINING: epoch0, iter700, loss: 0.8611001968383789\n",
      "TRAINING: epoch0, iter800, loss: 0.8776086568832397\n",
      "TRAINING: epoch0, iter900, loss: 0.8788787126541138\n",
      "TRAINING: epoch0, iter1000, loss: 0.8985704779624939\n",
      "TRAINING: epoch0, iter1100, loss: 0.8978380560874939\n",
      "TRAINING: epoch0, iter1200, loss: 0.9310212135314941\n",
      "TRAINING: epoch0, iter1300, loss: 0.8735507726669312\n",
      "Finish epoch 0, time elapsed 503.0627861022949\n",
      "VALIDATION: iter0, loss: 0.8026032447814941\n",
      "VALIDATION: iter100, loss: 0.7754031419754028\n",
      "VALIDATION: iter200, loss: 0.8013245463371277\n",
      "VALIDATION: iter300, loss: 0.7891312837600708\n",
      "Validation epoch 0: avg_iou = 0.432058930574958, avg_acc = 0.5915491977734352\n",
      "Saving best model after 0 epochs.\n",
      "Epoch: 1\n",
      "TRAINING: epoch1, iter0, loss: 0.8562037944793701\n",
      "TRAINING: epoch1, iter100, loss: 0.8016886711120605\n",
      "TRAINING: epoch1, iter200, loss: 0.8969914317131042\n",
      "TRAINING: epoch1, iter300, loss: 0.907714307308197\n",
      "TRAINING: epoch1, iter400, loss: 0.8832471370697021\n",
      "TRAINING: epoch1, iter500, loss: 0.8676838874816895\n",
      "TRAINING: epoch1, iter600, loss: 0.8586512804031372\n",
      "TRAINING: epoch1, iter700, loss: 0.8983812928199768\n",
      "TRAINING: epoch1, iter800, loss: 0.8293193578720093\n",
      "TRAINING: epoch1, iter900, loss: 0.8167510032653809\n",
      "TRAINING: epoch1, iter1000, loss: 0.8641452193260193\n",
      "TRAINING: epoch1, iter1100, loss: 0.83915776014328\n",
      "TRAINING: epoch1, iter1200, loss: 0.8241155743598938\n",
      "TRAINING: epoch1, iter1300, loss: 0.8180385828018188\n",
      "Finish epoch 1, time elapsed 258.8651912212372\n",
      "VALIDATION: iter0, loss: 0.7714651226997375\n",
      "VALIDATION: iter100, loss: 0.7855308055877686\n",
      "VALIDATION: iter200, loss: 0.7783524990081787\n",
      "VALIDATION: iter300, loss: 0.8203610181808472\n",
      "Validation epoch 1: avg_iou = 0.45196458323677974, avg_acc = 0.6117274545911533\n",
      "Saving best model after 1 epochs.\n",
      "Epoch: 2\n",
      "TRAINING: epoch2, iter0, loss: 0.8789314031600952\n",
      "TRAINING: epoch2, iter100, loss: 0.8210157752037048\n",
      "TRAINING: epoch2, iter200, loss: 0.8829428553581238\n",
      "TRAINING: epoch2, iter300, loss: 0.9055417776107788\n",
      "TRAINING: epoch2, iter400, loss: 0.9100557565689087\n",
      "TRAINING: epoch2, iter500, loss: 0.8318572044372559\n",
      "TRAINING: epoch2, iter600, loss: 0.8072978258132935\n",
      "TRAINING: epoch2, iter700, loss: 0.8406723737716675\n",
      "TRAINING: epoch2, iter800, loss: 0.8197921514511108\n",
      "TRAINING: epoch2, iter900, loss: 0.8468734622001648\n",
      "TRAINING: epoch2, iter1000, loss: 0.8678962588310242\n",
      "TRAINING: epoch2, iter1100, loss: 0.8776977062225342\n",
      "TRAINING: epoch2, iter1200, loss: 0.8060034513473511\n",
      "TRAINING: epoch2, iter1300, loss: 0.8732630014419556\n",
      "Finish epoch 2, time elapsed 191.72334623336792\n",
      "VALIDATION: iter0, loss: 0.7711424231529236\n",
      "VALIDATION: iter100, loss: 0.7502376437187195\n",
      "VALIDATION: iter200, loss: 0.7422077655792236\n",
      "VALIDATION: iter300, loss: 0.7142852544784546\n",
      "Validation epoch 2: avg_iou = 0.5207937082247948, avg_acc = 0.6734639544095566\n",
      "Saving best model after 2 epochs.\n",
      "Epoch: 3\n",
      "TRAINING: epoch3, iter0, loss: 0.8482394814491272\n",
      "TRAINING: epoch3, iter100, loss: 0.8406986594200134\n",
      "TRAINING: epoch3, iter200, loss: 0.899480402469635\n",
      "TRAINING: epoch3, iter300, loss: 0.8867498636245728\n",
      "TRAINING: epoch3, iter400, loss: 0.8279181718826294\n",
      "TRAINING: epoch3, iter500, loss: 0.8740903735160828\n",
      "TRAINING: epoch3, iter600, loss: 0.8495281934738159\n",
      "TRAINING: epoch3, iter700, loss: 0.8768607974052429\n",
      "TRAINING: epoch3, iter800, loss: 0.8165754079818726\n",
      "TRAINING: epoch3, iter900, loss: 0.8245636224746704\n",
      "TRAINING: epoch3, iter1000, loss: 0.8259782791137695\n",
      "TRAINING: epoch3, iter1100, loss: 0.8577706813812256\n",
      "TRAINING: epoch3, iter1200, loss: 0.8376889824867249\n",
      "TRAINING: epoch3, iter1300, loss: 0.8618816137313843\n",
      "Finish epoch 3, time elapsed 190.12670016288757\n",
      "VALIDATION: iter0, loss: 0.7447153329849243\n",
      "VALIDATION: iter100, loss: 0.7798922657966614\n",
      "VALIDATION: iter200, loss: 0.7506593465805054\n",
      "VALIDATION: iter300, loss: 0.8237056136131287\n",
      "Validation epoch 3: avg_iou = 0.466341112087022, avg_acc = 0.624282492986366\n",
      "Epoch: 4\n",
      "TRAINING: epoch4, iter0, loss: 0.8826924562454224\n",
      "TRAINING: epoch4, iter100, loss: 0.9028657674789429\n",
      "TRAINING: epoch4, iter200, loss: 0.7813379764556885\n",
      "TRAINING: epoch4, iter300, loss: 0.8972386717796326\n",
      "TRAINING: epoch4, iter400, loss: 0.8363519906997681\n",
      "TRAINING: epoch4, iter500, loss: 0.899517834186554\n",
      "TRAINING: epoch4, iter600, loss: 0.8571293354034424\n",
      "TRAINING: epoch4, iter700, loss: 0.8333824276924133\n",
      "TRAINING: epoch4, iter800, loss: 0.9056000709533691\n",
      "TRAINING: epoch4, iter900, loss: 0.7912831902503967\n",
      "TRAINING: epoch4, iter1000, loss: 0.8114334940910339\n",
      "TRAINING: epoch4, iter1100, loss: 0.9045547842979431\n",
      "TRAINING: epoch4, iter1200, loss: 0.8147491216659546\n",
      "TRAINING: epoch4, iter1300, loss: 0.811722993850708\n",
      "Finish epoch 4, time elapsed 188.18081903457642\n",
      "VALIDATION: iter0, loss: 0.7441365718841553\n",
      "VALIDATION: iter100, loss: 0.7485845685005188\n",
      "VALIDATION: iter200, loss: 0.747551679611206\n",
      "VALIDATION: iter300, loss: 0.7157790064811707\n",
      "Validation epoch 4: avg_iou = 0.5218488153237015, avg_acc = 0.6749052588619403\n",
      "Saving best model after 4 epochs.\n",
      "Epoch: 5\n",
      "TRAINING: epoch5, iter0, loss: 0.8626735210418701\n",
      "TRAINING: epoch5, iter100, loss: 0.7926355004310608\n",
      "TRAINING: epoch5, iter200, loss: 0.8522998094558716\n",
      "TRAINING: epoch5, iter300, loss: 0.755340039730072\n",
      "TRAINING: epoch5, iter400, loss: 0.8711628317832947\n",
      "TRAINING: epoch5, iter500, loss: 0.8610838651657104\n",
      "TRAINING: epoch5, iter600, loss: 0.8492777943611145\n",
      "TRAINING: epoch5, iter700, loss: 0.8331748843193054\n",
      "TRAINING: epoch5, iter800, loss: 0.8258935213088989\n",
      "TRAINING: epoch5, iter900, loss: 0.8586499094963074\n",
      "TRAINING: epoch5, iter1000, loss: 0.8160653710365295\n",
      "TRAINING: epoch5, iter1100, loss: 0.9009891748428345\n",
      "TRAINING: epoch5, iter1200, loss: 0.8922300338745117\n",
      "TRAINING: epoch5, iter1300, loss: 0.7432092428207397\n",
      "Finish epoch 5, time elapsed 188.0848572254181\n",
      "VALIDATION: iter0, loss: 0.7347588539123535\n",
      "VALIDATION: iter100, loss: 0.7047802805900574\n",
      "VALIDATION: iter200, loss: 0.7191714644432068\n",
      "VALIDATION: iter300, loss: 0.724107027053833\n",
      "Validation epoch 5: avg_iou = 0.518154244191611, avg_acc = 0.6723988573942612\n",
      "Saving best model after 5 epochs.\n",
      "Epoch: 6\n",
      "TRAINING: epoch6, iter0, loss: 0.8602296710014343\n",
      "TRAINING: epoch6, iter100, loss: 0.8051667213439941\n",
      "TRAINING: epoch6, iter200, loss: 0.9163738489151001\n",
      "TRAINING: epoch6, iter300, loss: 0.8543789386749268\n",
      "TRAINING: epoch6, iter400, loss: 0.8201465606689453\n",
      "TRAINING: epoch6, iter500, loss: 0.8859500288963318\n",
      "TRAINING: epoch6, iter600, loss: 0.8982428908348083\n",
      "TRAINING: epoch6, iter700, loss: 0.8813913464546204\n",
      "TRAINING: epoch6, iter800, loss: 0.8272225260734558\n",
      "TRAINING: epoch6, iter900, loss: 0.7942459583282471\n",
      "TRAINING: epoch6, iter1000, loss: 0.862473726272583\n",
      "TRAINING: epoch6, iter1100, loss: 0.80730140209198\n",
      "TRAINING: epoch6, iter1200, loss: 0.8033347129821777\n",
      "TRAINING: epoch6, iter1300, loss: 0.8347494006156921\n",
      "Finish epoch 6, time elapsed 190.9938862323761\n",
      "VALIDATION: iter0, loss: 0.7476240396499634\n",
      "VALIDATION: iter100, loss: 0.7632696628570557\n",
      "VALIDATION: iter200, loss: 0.7366102933883667\n",
      "VALIDATION: iter300, loss: 0.7131540775299072\n",
      "Validation epoch 6: avg_iou = 0.5359176612612027, avg_acc = 0.6864459909609895\n",
      "Epoch: 7\n",
      "TRAINING: epoch7, iter0, loss: 0.8161717057228088\n",
      "TRAINING: epoch7, iter100, loss: 0.7945895195007324\n",
      "TRAINING: epoch7, iter200, loss: 0.7609332203865051\n",
      "TRAINING: epoch7, iter300, loss: 0.7455497980117798\n",
      "TRAINING: epoch7, iter400, loss: 0.7832368612289429\n",
      "TRAINING: epoch7, iter500, loss: 0.85853511095047\n",
      "TRAINING: epoch7, iter600, loss: 0.7952562570571899\n",
      "TRAINING: epoch7, iter700, loss: 0.8181666731834412\n",
      "TRAINING: epoch7, iter800, loss: 0.8096640110015869\n",
      "TRAINING: epoch7, iter900, loss: 0.7845262289047241\n",
      "TRAINING: epoch7, iter1000, loss: 0.8041718602180481\n",
      "TRAINING: epoch7, iter1100, loss: 0.8164406418800354\n",
      "TRAINING: epoch7, iter1200, loss: 0.8271586894989014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch7, iter1300, loss: 0.7556344270706177\n",
      "Finish epoch 7, time elapsed 186.30001711845398\n",
      "VALIDATION: iter0, loss: 0.7478243112564087\n",
      "VALIDATION: iter100, loss: 0.734595775604248\n",
      "VALIDATION: iter200, loss: 0.7214294672012329\n",
      "VALIDATION: iter300, loss: 0.7239120006561279\n",
      "Validation epoch 7: avg_iou = 0.5552925138331172, avg_acc = 0.7037228646563061\n",
      "Saving best model after 7 epochs.\n",
      "Epoch: 8\n",
      "TRAINING: epoch8, iter0, loss: 0.7601715326309204\n",
      "TRAINING: epoch8, iter100, loss: 0.8978896141052246\n",
      "TRAINING: epoch8, iter200, loss: 0.8483113050460815\n",
      "TRAINING: epoch8, iter300, loss: 0.8490155935287476\n",
      "TRAINING: epoch8, iter400, loss: 0.8004217743873596\n",
      "TRAINING: epoch8, iter500, loss: 0.8149522542953491\n",
      "TRAINING: epoch8, iter600, loss: 0.7906596660614014\n",
      "TRAINING: epoch8, iter700, loss: 0.7678216099739075\n",
      "TRAINING: epoch8, iter800, loss: 0.815248966217041\n",
      "TRAINING: epoch8, iter900, loss: 0.7717954516410828\n",
      "TRAINING: epoch8, iter1000, loss: 0.8663367033004761\n",
      "TRAINING: epoch8, iter1100, loss: 0.8081207871437073\n",
      "TRAINING: epoch8, iter1200, loss: 0.8542701005935669\n",
      "TRAINING: epoch8, iter1300, loss: 0.7848547697067261\n",
      "Finish epoch 8, time elapsed 188.90691566467285\n",
      "VALIDATION: iter0, loss: 0.7151911854743958\n",
      "VALIDATION: iter100, loss: 0.7526183128356934\n",
      "VALIDATION: iter200, loss: 0.7267097234725952\n",
      "VALIDATION: iter300, loss: 0.7353948354721069\n",
      "Validation epoch 8: avg_iou = 0.5461242640196388, avg_acc = 0.6979796187201542\n",
      "Saving best model after 8 epochs.\n",
      "Epoch: 9\n",
      "TRAINING: epoch9, iter0, loss: 0.871044397354126\n",
      "TRAINING: epoch9, iter100, loss: 0.7499356269836426\n",
      "TRAINING: epoch9, iter200, loss: 0.8267879486083984\n",
      "TRAINING: epoch9, iter300, loss: 0.832601010799408\n",
      "TRAINING: epoch9, iter400, loss: 0.8724708557128906\n",
      "TRAINING: epoch9, iter500, loss: 0.8781906366348267\n",
      "TRAINING: epoch9, iter600, loss: 0.8857561349868774\n",
      "TRAINING: epoch9, iter700, loss: 0.7830129265785217\n",
      "TRAINING: epoch9, iter800, loss: 0.8237464427947998\n",
      "TRAINING: epoch9, iter900, loss: 0.8483884334564209\n",
      "TRAINING: epoch9, iter1000, loss: 0.8266823291778564\n",
      "TRAINING: epoch9, iter1100, loss: 0.7103002071380615\n",
      "TRAINING: epoch9, iter1200, loss: 0.831204891204834\n",
      "TRAINING: epoch9, iter1300, loss: 0.8509551882743835\n",
      "Finish epoch 9, time elapsed 186.35424137115479\n",
      "VALIDATION: iter0, loss: 0.7261265516281128\n",
      "VALIDATION: iter100, loss: 0.7267094254493713\n",
      "VALIDATION: iter200, loss: 0.77376389503479\n",
      "VALIDATION: iter300, loss: 0.7416983842849731\n",
      "Validation epoch 9: avg_iou = 0.5478279297921195, avg_acc = 0.6994279085700191\n",
      "Saving best model after 9 epochs.\n",
      "Epoch: 10\n",
      "TRAINING: epoch10, iter0, loss: 0.8278678059577942\n",
      "TRAINING: epoch10, iter100, loss: 0.8679124116897583\n",
      "TRAINING: epoch10, iter200, loss: 0.8770009875297546\n",
      "TRAINING: epoch10, iter300, loss: 0.8702520728111267\n",
      "TRAINING: epoch10, iter400, loss: 0.8082555532455444\n",
      "TRAINING: epoch10, iter500, loss: 0.7986278533935547\n",
      "TRAINING: epoch10, iter600, loss: 0.7875227928161621\n",
      "TRAINING: epoch10, iter700, loss: 0.8389568328857422\n",
      "TRAINING: epoch10, iter800, loss: 0.814010739326477\n",
      "TRAINING: epoch10, iter900, loss: 0.8064342737197876\n",
      "TRAINING: epoch10, iter1000, loss: 0.7753099203109741\n",
      "TRAINING: epoch10, iter1100, loss: 0.7627346515655518\n",
      "TRAINING: epoch10, iter1200, loss: 0.8419754505157471\n",
      "TRAINING: epoch10, iter1300, loss: 0.816893458366394\n",
      "Finish epoch 10, time elapsed 186.09424591064453\n",
      "VALIDATION: iter0, loss: 0.7476075887680054\n",
      "VALIDATION: iter100, loss: 0.7232911586761475\n",
      "VALIDATION: iter200, loss: 0.7254290580749512\n",
      "VALIDATION: iter300, loss: 0.7053124904632568\n",
      "Validation epoch 10: avg_iou = 0.5610611604220832, avg_acc = 0.7099911549198094\n",
      "Saving best model after 10 epochs.\n",
      "Epoch: 11\n",
      "TRAINING: epoch11, iter0, loss: 0.8662940859794617\n",
      "TRAINING: epoch11, iter100, loss: 0.8229246139526367\n",
      "TRAINING: epoch11, iter200, loss: 0.7261183261871338\n",
      "TRAINING: epoch11, iter300, loss: 0.7648264765739441\n",
      "TRAINING: epoch11, iter400, loss: 0.7875763773918152\n",
      "TRAINING: epoch11, iter500, loss: 0.7882325053215027\n",
      "TRAINING: epoch11, iter600, loss: 0.7673826217651367\n",
      "TRAINING: epoch11, iter700, loss: 0.7860300540924072\n",
      "TRAINING: epoch11, iter800, loss: 0.8932469487190247\n",
      "TRAINING: epoch11, iter900, loss: 0.8484659194946289\n",
      "TRAINING: epoch11, iter1000, loss: 0.7930396795272827\n",
      "TRAINING: epoch11, iter1100, loss: 0.8307753205299377\n",
      "TRAINING: epoch11, iter1200, loss: 0.8467724323272705\n",
      "TRAINING: epoch11, iter1300, loss: 0.8552082777023315\n",
      "Finish epoch 11, time elapsed 187.7873363494873\n",
      "VALIDATION: iter0, loss: 0.7226341962814331\n",
      "VALIDATION: iter100, loss: 0.7263785600662231\n",
      "VALIDATION: iter200, loss: 0.7468796968460083\n",
      "VALIDATION: iter300, loss: 0.7407269477844238\n",
      "Validation epoch 11: avg_iou = 0.5695882298163514, avg_acc = 0.7164751517238902\n",
      "Saving best model after 11 epochs.\n",
      "Epoch: 12\n",
      "TRAINING: epoch12, iter0, loss: 0.8339987397193909\n",
      "TRAINING: epoch12, iter100, loss: 0.7915171980857849\n",
      "TRAINING: epoch12, iter200, loss: 0.8814230561256409\n",
      "TRAINING: epoch12, iter300, loss: 0.7829768657684326\n",
      "TRAINING: epoch12, iter400, loss: 0.8560657501220703\n",
      "TRAINING: epoch12, iter500, loss: 0.7155708074569702\n",
      "TRAINING: epoch12, iter600, loss: 0.8515535593032837\n",
      "TRAINING: epoch12, iter700, loss: 0.8098778128623962\n",
      "TRAINING: epoch12, iter800, loss: 0.8132169246673584\n",
      "TRAINING: epoch12, iter900, loss: 0.8696961998939514\n",
      "TRAINING: epoch12, iter1000, loss: 0.8019446134567261\n",
      "TRAINING: epoch12, iter1100, loss: 0.8983367085456848\n",
      "TRAINING: epoch12, iter1200, loss: 0.9117569327354431\n",
      "TRAINING: epoch12, iter1300, loss: 0.7711716294288635\n",
      "Finish epoch 12, time elapsed 187.3344464302063\n",
      "VALIDATION: iter0, loss: 0.7517302632331848\n",
      "VALIDATION: iter100, loss: 0.7152379751205444\n",
      "VALIDATION: iter200, loss: 0.7366736531257629\n",
      "VALIDATION: iter300, loss: 0.7306885123252869\n",
      "Validation epoch 12: avg_iou = 0.5352999412301761, avg_acc = 0.6884138358173085\n",
      "Epoch: 13\n",
      "TRAINING: epoch13, iter0, loss: 0.9116547107696533\n",
      "TRAINING: epoch13, iter100, loss: 0.7198887467384338\n",
      "TRAINING: epoch13, iter200, loss: 0.8025546073913574\n",
      "TRAINING: epoch13, iter300, loss: 0.813957691192627\n",
      "TRAINING: epoch13, iter400, loss: 0.7869163155555725\n",
      "TRAINING: epoch13, iter500, loss: 0.7819359302520752\n",
      "TRAINING: epoch13, iter600, loss: 0.8994668126106262\n",
      "TRAINING: epoch13, iter700, loss: 0.7524428367614746\n",
      "TRAINING: epoch13, iter800, loss: 0.7797937989234924\n",
      "TRAINING: epoch13, iter900, loss: 0.7935729026794434\n",
      "TRAINING: epoch13, iter1000, loss: 0.8443174958229065\n",
      "TRAINING: epoch13, iter1100, loss: 0.9263041615486145\n",
      "TRAINING: epoch13, iter1200, loss: 0.8446177244186401\n",
      "TRAINING: epoch13, iter1300, loss: 0.8532049655914307\n",
      "Finish epoch 13, time elapsed 186.53923273086548\n",
      "VALIDATION: iter0, loss: 0.7374775409698486\n",
      "VALIDATION: iter100, loss: 0.7018111944198608\n",
      "VALIDATION: iter200, loss: 0.7004605531692505\n",
      "VALIDATION: iter300, loss: 0.6979748010635376\n",
      "Validation epoch 13: avg_iou = 0.5659462866498464, avg_acc = 0.7142469827808551\n",
      "Epoch: 14\n",
      "TRAINING: epoch14, iter0, loss: 0.8008965253829956\n",
      "TRAINING: epoch14, iter100, loss: 0.8266316056251526\n",
      "TRAINING: epoch14, iter200, loss: 0.8501495122909546\n",
      "TRAINING: epoch14, iter300, loss: 0.7776082158088684\n",
      "TRAINING: epoch14, iter400, loss: 0.7845849990844727\n",
      "TRAINING: epoch14, iter500, loss: 0.7790954113006592\n",
      "TRAINING: epoch14, iter600, loss: 0.7613731026649475\n",
      "TRAINING: epoch14, iter700, loss: 0.7313312292098999\n",
      "TRAINING: epoch14, iter800, loss: 0.8553360104560852\n",
      "TRAINING: epoch14, iter900, loss: 0.8310256004333496\n",
      "TRAINING: epoch14, iter1000, loss: 0.8504770994186401\n",
      "TRAINING: epoch14, iter1100, loss: 0.7568767666816711\n",
      "TRAINING: epoch14, iter1200, loss: 0.8277326226234436\n",
      "TRAINING: epoch14, iter1300, loss: 0.8447189331054688\n",
      "Finish epoch 14, time elapsed 188.07175159454346\n",
      "VALIDATION: iter0, loss: 0.7099539637565613\n",
      "VALIDATION: iter100, loss: 0.7282838821411133\n",
      "VALIDATION: iter200, loss: 0.7013720870018005\n",
      "VALIDATION: iter300, loss: 0.728535532951355\n",
      "Validation epoch 14: avg_iou = 0.5734625590381338, avg_acc = 0.7198501798643995\n",
      "Saving best model after 14 epochs.\n",
      "Epoch: 15\n",
      "TRAINING: epoch15, iter0, loss: 0.8544153571128845\n",
      "TRAINING: epoch15, iter100, loss: 0.8246906399726868\n",
      "TRAINING: epoch15, iter200, loss: 0.8435451984405518\n",
      "TRAINING: epoch15, iter300, loss: 0.8083288073539734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch15, iter400, loss: 0.8347097635269165\n",
      "TRAINING: epoch15, iter500, loss: 0.8093237280845642\n",
      "TRAINING: epoch15, iter600, loss: 0.8237985372543335\n",
      "TRAINING: epoch15, iter700, loss: 0.9242044687271118\n",
      "TRAINING: epoch15, iter800, loss: 0.8371110558509827\n",
      "TRAINING: epoch15, iter900, loss: 0.8182249069213867\n",
      "TRAINING: epoch15, iter1000, loss: 0.731605052947998\n",
      "TRAINING: epoch15, iter1100, loss: 0.7501914501190186\n",
      "TRAINING: epoch15, iter1200, loss: 0.7120130062103271\n",
      "TRAINING: epoch15, iter1300, loss: 0.8576942682266235\n",
      "Finish epoch 15, time elapsed 189.0800883769989\n",
      "VALIDATION: iter0, loss: 0.7310858964920044\n",
      "VALIDATION: iter100, loss: 0.7024759650230408\n",
      "VALIDATION: iter200, loss: 0.7293789386749268\n",
      "VALIDATION: iter300, loss: 0.6887891292572021\n",
      "Validation epoch 15: avg_iou = 0.5757932070475905, avg_acc = 0.7221498855903967\n",
      "Saving best model after 15 epochs.\n",
      "Epoch: 16\n",
      "TRAINING: epoch16, iter0, loss: 0.7923262119293213\n",
      "TRAINING: epoch16, iter100, loss: 0.7922422885894775\n",
      "TRAINING: epoch16, iter200, loss: 0.8541994690895081\n",
      "TRAINING: epoch16, iter300, loss: 0.828567385673523\n",
      "TRAINING: epoch16, iter400, loss: 0.7783522605895996\n",
      "TRAINING: epoch16, iter500, loss: 0.7996873259544373\n",
      "TRAINING: epoch16, iter600, loss: 0.7630521059036255\n",
      "TRAINING: epoch16, iter700, loss: 0.8197866678237915\n",
      "TRAINING: epoch16, iter800, loss: 0.8875643014907837\n",
      "TRAINING: epoch16, iter900, loss: 0.7693487405776978\n",
      "TRAINING: epoch16, iter1000, loss: 0.8872602581977844\n",
      "TRAINING: epoch16, iter1100, loss: 0.8890034556388855\n",
      "TRAINING: epoch16, iter1200, loss: 0.8403822183609009\n",
      "TRAINING: epoch16, iter1300, loss: 0.7840589284896851\n",
      "Finish epoch 16, time elapsed 188.63101196289062\n",
      "VALIDATION: iter0, loss: 0.7383764982223511\n",
      "VALIDATION: iter100, loss: 0.7286998629570007\n",
      "VALIDATION: iter200, loss: 0.7130905389785767\n",
      "VALIDATION: iter300, loss: 0.6965417861938477\n",
      "Validation epoch 16: avg_iou = 0.5780599852106465, avg_acc = 0.7235132391773053\n",
      "Epoch: 17\n",
      "TRAINING: epoch17, iter0, loss: 0.8529327511787415\n",
      "TRAINING: epoch17, iter100, loss: 0.8720406293869019\n",
      "TRAINING: epoch17, iter200, loss: 0.7616581320762634\n",
      "TRAINING: epoch17, iter300, loss: 0.8561684489250183\n",
      "TRAINING: epoch17, iter400, loss: 0.8047327399253845\n",
      "TRAINING: epoch17, iter500, loss: 0.8375878930091858\n",
      "TRAINING: epoch17, iter600, loss: 0.7546474933624268\n",
      "TRAINING: epoch17, iter700, loss: 0.7424042820930481\n",
      "TRAINING: epoch17, iter800, loss: 0.800547182559967\n",
      "TRAINING: epoch17, iter900, loss: 0.8801169395446777\n",
      "TRAINING: epoch17, iter1000, loss: 0.7719480991363525\n",
      "TRAINING: epoch17, iter1100, loss: 0.8409227132797241\n",
      "TRAINING: epoch17, iter1200, loss: 0.82761549949646\n",
      "TRAINING: epoch17, iter1300, loss: 0.8302347660064697\n",
      "Finish epoch 17, time elapsed 190.7468855381012\n",
      "VALIDATION: iter0, loss: 0.7093815207481384\n",
      "VALIDATION: iter100, loss: 0.7115439176559448\n",
      "VALIDATION: iter200, loss: 0.7115504145622253\n",
      "VALIDATION: iter300, loss: 0.7085702419281006\n",
      "Validation epoch 17: avg_iou = 0.5752582797363622, avg_acc = 0.7211939188971448\n",
      "Epoch: 18\n",
      "TRAINING: epoch18, iter0, loss: 0.733379602432251\n",
      "TRAINING: epoch18, iter100, loss: 0.7921562790870667\n",
      "TRAINING: epoch18, iter200, loss: 0.817813515663147\n",
      "TRAINING: epoch18, iter300, loss: 0.9201076030731201\n",
      "TRAINING: epoch18, iter400, loss: 0.7464742064476013\n",
      "TRAINING: epoch18, iter500, loss: 0.8538769483566284\n",
      "TRAINING: epoch18, iter600, loss: 0.7581971287727356\n",
      "TRAINING: epoch18, iter700, loss: 0.7935117483139038\n",
      "TRAINING: epoch18, iter800, loss: 0.8680984973907471\n",
      "TRAINING: epoch18, iter900, loss: 0.7833123803138733\n",
      "TRAINING: epoch18, iter1000, loss: 0.8022657632827759\n",
      "TRAINING: epoch18, iter1100, loss: 0.7901662588119507\n",
      "TRAINING: epoch18, iter1200, loss: 0.8850894570350647\n",
      "TRAINING: epoch18, iter1300, loss: 0.8260257244110107\n",
      "Finish epoch 18, time elapsed 186.22364854812622\n",
      "VALIDATION: iter0, loss: 0.7227644920349121\n",
      "VALIDATION: iter100, loss: 0.7155890464782715\n",
      "VALIDATION: iter200, loss: 0.7363873720169067\n",
      "VALIDATION: iter300, loss: 0.7219305038452148\n",
      "Validation epoch 18: avg_iou = 0.5732939648094462, avg_acc = 0.720977776975774\n",
      "Saving best model after 18 epochs.\n",
      "Epoch: 19\n",
      "TRAINING: epoch19, iter0, loss: 0.781179666519165\n",
      "TRAINING: epoch19, iter100, loss: 0.8477450609207153\n",
      "TRAINING: epoch19, iter200, loss: 0.7630254626274109\n",
      "TRAINING: epoch19, iter300, loss: 0.7907888889312744\n",
      "TRAINING: epoch19, iter400, loss: 0.7583714127540588\n",
      "TRAINING: epoch19, iter500, loss: 0.8691919445991516\n",
      "TRAINING: epoch19, iter600, loss: 0.7725328803062439\n",
      "TRAINING: epoch19, iter700, loss: 0.8836002349853516\n",
      "TRAINING: epoch19, iter800, loss: 0.8246074914932251\n",
      "TRAINING: epoch19, iter900, loss: 0.791654109954834\n",
      "TRAINING: epoch19, iter1000, loss: 0.8652459383010864\n",
      "TRAINING: epoch19, iter1100, loss: 0.7123715877532959\n",
      "TRAINING: epoch19, iter1200, loss: 0.7293376922607422\n",
      "TRAINING: epoch19, iter1300, loss: 0.8549866080284119\n",
      "Finish epoch 19, time elapsed 186.89225053787231\n",
      "VALIDATION: iter0, loss: 0.7302672266960144\n",
      "VALIDATION: iter100, loss: 0.7465376257896423\n",
      "VALIDATION: iter200, loss: 0.6912228465080261\n",
      "VALIDATION: iter300, loss: 0.7132836580276489\n",
      "Validation epoch 19: avg_iou = 0.5841345545960897, avg_acc = 0.7291400281351004\n",
      "Saving best model after 19 epochs.\n",
      "Epoch: 20\n",
      "TRAINING: epoch20, iter0, loss: 0.781197190284729\n",
      "TRAINING: epoch20, iter100, loss: 0.774856686592102\n",
      "TRAINING: epoch20, iter200, loss: 0.6893441677093506\n",
      "TRAINING: epoch20, iter300, loss: 0.7489291429519653\n",
      "TRAINING: epoch20, iter400, loss: 0.8293439149856567\n",
      "TRAINING: epoch20, iter500, loss: 0.860107421875\n",
      "TRAINING: epoch20, iter600, loss: 0.7917745113372803\n",
      "TRAINING: epoch20, iter700, loss: 0.8480303287506104\n",
      "TRAINING: epoch20, iter800, loss: 0.8110912442207336\n",
      "TRAINING: epoch20, iter900, loss: 0.7818911671638489\n",
      "TRAINING: epoch20, iter1000, loss: 0.7772453427314758\n",
      "TRAINING: epoch20, iter1100, loss: 0.8290136456489563\n",
      "TRAINING: epoch20, iter1200, loss: 0.7834697961807251\n",
      "TRAINING: epoch20, iter1300, loss: 0.8226982951164246\n",
      "Finish epoch 20, time elapsed 188.10493898391724\n",
      "VALIDATION: iter0, loss: 0.69184410572052\n",
      "VALIDATION: iter100, loss: 0.7303929328918457\n",
      "VALIDATION: iter200, loss: 0.7169635891914368\n",
      "VALIDATION: iter300, loss: 0.725378155708313\n",
      "Validation epoch 20: avg_iou = 0.5765775700113667, avg_acc = 0.7233722612039367\n",
      "Epoch: 21\n",
      "TRAINING: epoch21, iter0, loss: 0.8223390579223633\n",
      "TRAINING: epoch21, iter100, loss: 0.8706963062286377\n",
      "TRAINING: epoch21, iter200, loss: 0.7707701921463013\n",
      "TRAINING: epoch21, iter300, loss: 0.7633524537086487\n",
      "TRAINING: epoch21, iter400, loss: 0.9249323010444641\n",
      "TRAINING: epoch21, iter500, loss: 0.9194484353065491\n",
      "TRAINING: epoch21, iter600, loss: 0.8160281181335449\n",
      "TRAINING: epoch21, iter700, loss: 0.829078197479248\n",
      "TRAINING: epoch21, iter800, loss: 0.8026169538497925\n",
      "TRAINING: epoch21, iter900, loss: 0.7267746329307556\n",
      "TRAINING: epoch21, iter1000, loss: 0.7615456581115723\n",
      "TRAINING: epoch21, iter1100, loss: 0.8630903959274292\n",
      "TRAINING: epoch21, iter1200, loss: 0.8115365505218506\n",
      "TRAINING: epoch21, iter1300, loss: 0.7071747779846191\n",
      "Finish epoch 21, time elapsed 188.36748504638672\n",
      "VALIDATION: iter0, loss: 0.720279335975647\n",
      "VALIDATION: iter100, loss: 0.7218748331069946\n",
      "VALIDATION: iter200, loss: 0.7543079257011414\n",
      "VALIDATION: iter300, loss: 0.7051804065704346\n",
      "Validation epoch 21: avg_iou = 0.5738058266355031, avg_acc = 0.721101468534612\n",
      "Epoch: 22\n",
      "TRAINING: epoch22, iter0, loss: 0.8000174760818481\n",
      "TRAINING: epoch22, iter100, loss: 0.8352107405662537\n",
      "TRAINING: epoch22, iter200, loss: 0.8007702827453613\n",
      "TRAINING: epoch22, iter300, loss: 0.7969059348106384\n",
      "TRAINING: epoch22, iter400, loss: 0.8746436238288879\n",
      "TRAINING: epoch22, iter500, loss: 0.7987686991691589\n",
      "TRAINING: epoch22, iter600, loss: 0.7781735062599182\n",
      "TRAINING: epoch22, iter700, loss: 0.8334633111953735\n",
      "TRAINING: epoch22, iter800, loss: 0.8061028718948364\n",
      "TRAINING: epoch22, iter900, loss: 0.8020563721656799\n",
      "TRAINING: epoch22, iter1000, loss: 0.6921644806861877\n",
      "TRAINING: epoch22, iter1100, loss: 0.7988547682762146\n",
      "TRAINING: epoch22, iter1200, loss: 0.803627073764801\n",
      "TRAINING: epoch22, iter1300, loss: 0.7187827825546265\n",
      "Finish epoch 22, time elapsed 187.62682795524597\n",
      "VALIDATION: iter0, loss: 0.709001362323761\n",
      "VALIDATION: iter100, loss: 0.7140276432037354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: iter200, loss: 0.7147917747497559\n",
      "VALIDATION: iter300, loss: 0.7272579073905945\n",
      "Validation epoch 22: avg_iou = 0.5759143610498798, avg_acc = 0.7230244762861907\n",
      "Epoch: 23\n",
      "TRAINING: epoch23, iter0, loss: 0.7387741208076477\n",
      "TRAINING: epoch23, iter100, loss: 0.8061855435371399\n",
      "TRAINING: epoch23, iter200, loss: 0.8098458051681519\n",
      "TRAINING: epoch23, iter300, loss: 0.7683017253875732\n",
      "TRAINING: epoch23, iter400, loss: 0.7642101645469666\n",
      "TRAINING: epoch23, iter500, loss: 0.7747700810432434\n",
      "TRAINING: epoch23, iter600, loss: 0.8457177877426147\n",
      "TRAINING: epoch23, iter700, loss: 0.8452669978141785\n",
      "TRAINING: epoch23, iter800, loss: 0.796502947807312\n",
      "TRAINING: epoch23, iter900, loss: 0.718874454498291\n",
      "TRAINING: epoch23, iter1000, loss: 0.8432426452636719\n",
      "TRAINING: epoch23, iter1100, loss: 0.8213374018669128\n",
      "TRAINING: epoch23, iter1200, loss: 0.7869235277175903\n",
      "TRAINING: epoch23, iter1300, loss: 0.6878145337104797\n",
      "Finish epoch 23, time elapsed 192.00524640083313\n",
      "VALIDATION: iter0, loss: 0.694998562335968\n",
      "VALIDATION: iter100, loss: 0.7171114683151245\n",
      "VALIDATION: iter200, loss: 0.696074366569519\n",
      "VALIDATION: iter300, loss: 0.7107623219490051\n",
      "Validation epoch 23: avg_iou = 0.5850732545354473, avg_acc = 0.7297498320465657\n",
      "Epoch: 24\n",
      "TRAINING: epoch24, iter0, loss: 0.674550473690033\n",
      "TRAINING: epoch24, iter100, loss: 0.9044447541236877\n",
      "TRAINING: epoch24, iter200, loss: 0.7660802602767944\n",
      "TRAINING: epoch24, iter300, loss: 0.7979823350906372\n",
      "TRAINING: epoch24, iter400, loss: 0.7918910980224609\n",
      "TRAINING: epoch24, iter500, loss: 0.8671002388000488\n",
      "TRAINING: epoch24, iter600, loss: 0.8891826868057251\n",
      "TRAINING: epoch24, iter700, loss: 0.7646608352661133\n",
      "TRAINING: epoch24, iter800, loss: 0.7810645699501038\n",
      "TRAINING: epoch24, iter900, loss: 0.8289361596107483\n",
      "TRAINING: epoch24, iter1000, loss: 0.7543293237686157\n",
      "TRAINING: epoch24, iter1100, loss: 0.7975757122039795\n",
      "TRAINING: epoch24, iter1200, loss: 0.833328127861023\n",
      "TRAINING: epoch24, iter1300, loss: 0.7853184342384338\n",
      "Finish epoch 24, time elapsed 188.4454803466797\n",
      "VALIDATION: iter0, loss: 0.7026402950286865\n",
      "VALIDATION: iter100, loss: 0.7085942029953003\n",
      "VALIDATION: iter200, loss: 0.7517196536064148\n",
      "VALIDATION: iter300, loss: 0.7041053175926208\n",
      "Validation epoch 24: avg_iou = 0.5704791999574917, avg_acc = 0.7184720074952539\n",
      "Epoch: 25\n",
      "TRAINING: epoch25, iter0, loss: 0.8043640851974487\n",
      "TRAINING: epoch25, iter100, loss: 0.8088939189910889\n",
      "TRAINING: epoch25, iter200, loss: 0.7377726435661316\n",
      "TRAINING: epoch25, iter300, loss: 0.7981376647949219\n",
      "TRAINING: epoch25, iter400, loss: 0.8383182287216187\n",
      "TRAINING: epoch25, iter500, loss: 0.781805694103241\n",
      "TRAINING: epoch25, iter600, loss: 0.7423858046531677\n",
      "TRAINING: epoch25, iter700, loss: 0.8227257132530212\n",
      "TRAINING: epoch25, iter800, loss: 0.8381448984146118\n",
      "TRAINING: epoch25, iter900, loss: 0.7493772506713867\n",
      "TRAINING: epoch25, iter1000, loss: 0.8887449502944946\n",
      "TRAINING: epoch25, iter1100, loss: 0.816759467124939\n",
      "TRAINING: epoch25, iter1200, loss: 0.827961802482605\n",
      "TRAINING: epoch25, iter1300, loss: 0.7978126406669617\n",
      "Finish epoch 25, time elapsed 192.63530349731445\n",
      "VALIDATION: iter0, loss: 0.7226145267486572\n",
      "VALIDATION: iter100, loss: 0.7237645387649536\n",
      "VALIDATION: iter200, loss: 0.7079421281814575\n",
      "VALIDATION: iter300, loss: 0.7082680463790894\n",
      "Validation epoch 25: avg_iou = 0.573579705829051, avg_acc = 0.7204118102344115\n",
      "Epoch: 26\n",
      "TRAINING: epoch26, iter0, loss: 0.8571472764015198\n",
      "TRAINING: epoch26, iter100, loss: 0.8011061549186707\n",
      "TRAINING: epoch26, iter200, loss: 0.9106826782226562\n",
      "TRAINING: epoch26, iter300, loss: 0.8320616483688354\n",
      "TRAINING: epoch26, iter400, loss: 0.7633621692657471\n",
      "TRAINING: epoch26, iter500, loss: 0.6446918249130249\n",
      "TRAINING: epoch26, iter600, loss: 0.7988683581352234\n",
      "TRAINING: epoch26, iter700, loss: 0.7916221618652344\n",
      "TRAINING: epoch26, iter800, loss: 0.9184084534645081\n",
      "TRAINING: epoch26, iter900, loss: 0.8193275928497314\n",
      "TRAINING: epoch26, iter1000, loss: 0.8150193095207214\n",
      "TRAINING: epoch26, iter1100, loss: 0.8151220679283142\n",
      "TRAINING: epoch26, iter1200, loss: 0.7575829029083252\n",
      "TRAINING: epoch26, iter1300, loss: 0.8193339109420776\n",
      "Finish epoch 26, time elapsed 194.09304094314575\n",
      "VALIDATION: iter0, loss: 0.6930893659591675\n",
      "VALIDATION: iter100, loss: 0.7033563852310181\n",
      "VALIDATION: iter200, loss: 0.718634843826294\n",
      "VALIDATION: iter300, loss: 0.7612626552581787\n",
      "Validation epoch 26: avg_iou = 0.5839295173758892, avg_acc = 0.7291003510133544\n",
      "Epoch: 27\n",
      "TRAINING: epoch27, iter0, loss: 0.7444469928741455\n",
      "TRAINING: epoch27, iter100, loss: 0.6867654323577881\n",
      "TRAINING: epoch27, iter200, loss: 0.8548122048377991\n",
      "TRAINING: epoch27, iter300, loss: 0.6213827729225159\n",
      "TRAINING: epoch27, iter400, loss: 0.8536527156829834\n",
      "TRAINING: epoch27, iter500, loss: 0.6288033723831177\n",
      "TRAINING: epoch27, iter600, loss: 0.8439830541610718\n",
      "TRAINING: epoch27, iter700, loss: 0.763481080532074\n",
      "TRAINING: epoch27, iter800, loss: 0.7802977561950684\n",
      "TRAINING: epoch27, iter900, loss: 0.7474584579467773\n",
      "TRAINING: epoch27, iter1000, loss: 0.8061673641204834\n",
      "TRAINING: epoch27, iter1100, loss: 0.7603983283042908\n",
      "TRAINING: epoch27, iter1200, loss: 0.8315174579620361\n",
      "TRAINING: epoch27, iter1300, loss: 0.8009968400001526\n",
      "Finish epoch 27, time elapsed 192.9278793334961\n",
      "VALIDATION: iter0, loss: 0.7285786867141724\n",
      "VALIDATION: iter100, loss: 0.731136679649353\n",
      "VALIDATION: iter200, loss: 0.742070198059082\n",
      "VALIDATION: iter300, loss: 0.6924381852149963\n",
      "Validation epoch 27: avg_iou = 0.5870697365767921, avg_acc = 0.7314675888018821\n",
      "Epoch: 28\n",
      "TRAINING: epoch28, iter0, loss: 0.7773234844207764\n",
      "TRAINING: epoch28, iter100, loss: 0.797511100769043\n",
      "TRAINING: epoch28, iter200, loss: 0.7685973644256592\n",
      "TRAINING: epoch28, iter300, loss: 0.7503787279129028\n",
      "TRAINING: epoch28, iter400, loss: 0.7455436587333679\n",
      "TRAINING: epoch28, iter500, loss: 0.8228945136070251\n",
      "TRAINING: epoch28, iter600, loss: 0.8565564751625061\n",
      "TRAINING: epoch28, iter700, loss: 0.8462647199630737\n",
      "TRAINING: epoch28, iter800, loss: 0.8195688724517822\n",
      "TRAINING: epoch28, iter900, loss: 0.7804346084594727\n",
      "TRAINING: epoch28, iter1000, loss: 0.8071502447128296\n",
      "TRAINING: epoch28, iter1100, loss: 0.6910629272460938\n",
      "TRAINING: epoch28, iter1200, loss: 0.8544891476631165\n",
      "TRAINING: epoch28, iter1300, loss: 0.794011652469635\n",
      "Finish epoch 28, time elapsed 186.76807928085327\n",
      "VALIDATION: iter0, loss: 0.7444369792938232\n",
      "VALIDATION: iter100, loss: 0.7457770705223083\n",
      "VALIDATION: iter200, loss: 0.7141214609146118\n",
      "VALIDATION: iter300, loss: 0.6944485306739807\n",
      "Validation epoch 28: avg_iou = 0.5749262801746824, avg_acc = 0.7225114765451915\n",
      "Epoch: 29\n",
      "TRAINING: epoch29, iter0, loss: 0.8253884315490723\n",
      "TRAINING: epoch29, iter100, loss: 0.7533544301986694\n",
      "TRAINING: epoch29, iter200, loss: 0.8170691132545471\n",
      "TRAINING: epoch29, iter300, loss: 0.779485821723938\n",
      "TRAINING: epoch29, iter400, loss: 0.7473110556602478\n",
      "TRAINING: epoch29, iter500, loss: 0.8046635389328003\n",
      "TRAINING: epoch29, iter600, loss: 0.8199801445007324\n",
      "TRAINING: epoch29, iter700, loss: 0.7717161178588867\n",
      "TRAINING: epoch29, iter800, loss: 0.6755445599555969\n",
      "TRAINING: epoch29, iter900, loss: 0.8515974283218384\n",
      "TRAINING: epoch29, iter1000, loss: 0.7957592010498047\n",
      "TRAINING: epoch29, iter1100, loss: 0.6936250925064087\n",
      "TRAINING: epoch29, iter1200, loss: 0.8736971616744995\n",
      "TRAINING: epoch29, iter1300, loss: 0.8584906458854675\n",
      "Finish epoch 29, time elapsed 188.59184765815735\n",
      "VALIDATION: iter0, loss: 0.6979271769523621\n",
      "VALIDATION: iter100, loss: 0.7145910263061523\n",
      "VALIDATION: iter200, loss: 0.7201528549194336\n",
      "VALIDATION: iter300, loss: 0.7302952408790588\n",
      "Validation epoch 29: avg_iou = 0.5876881056757116, avg_acc = 0.7327186394093642\n",
      "Saving best model after 29 epochs.\n",
      "Epoch: 30\n",
      "TRAINING: epoch30, iter0, loss: 0.7941802144050598\n",
      "TRAINING: epoch30, iter100, loss: 0.837164044380188\n",
      "TRAINING: epoch30, iter200, loss: 0.8422895073890686\n",
      "TRAINING: epoch30, iter300, loss: 0.9028213024139404\n",
      "TRAINING: epoch30, iter400, loss: 0.7816591262817383\n",
      "TRAINING: epoch30, iter500, loss: 0.8445185422897339\n",
      "TRAINING: epoch30, iter600, loss: 0.7333749532699585\n",
      "TRAINING: epoch30, iter700, loss: 0.8092818856239319\n",
      "TRAINING: epoch30, iter800, loss: 0.7803542017936707\n",
      "TRAINING: epoch30, iter900, loss: 0.8480263948440552\n",
      "TRAINING: epoch30, iter1000, loss: 0.7685254216194153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch30, iter1100, loss: 0.8671679496765137\n",
      "TRAINING: epoch30, iter1200, loss: 0.7908102869987488\n",
      "TRAINING: epoch30, iter1300, loss: 0.7372580766677856\n",
      "Finish epoch 30, time elapsed 186.48854994773865\n",
      "VALIDATION: iter0, loss: 0.7090933322906494\n",
      "VALIDATION: iter100, loss: 0.7068862318992615\n",
      "VALIDATION: iter200, loss: 0.7076122164726257\n",
      "VALIDATION: iter300, loss: 0.7126052379608154\n",
      "Validation epoch 30: avg_iou = 0.5893470573781142, avg_acc = 0.7332692491474436\n",
      "Epoch: 31\n",
      "TRAINING: epoch31, iter0, loss: 0.8342054486274719\n",
      "TRAINING: epoch31, iter100, loss: 0.8918938636779785\n",
      "TRAINING: epoch31, iter200, loss: 0.738814115524292\n",
      "TRAINING: epoch31, iter300, loss: 0.7987924218177795\n",
      "TRAINING: epoch31, iter400, loss: 0.7959927320480347\n",
      "TRAINING: epoch31, iter500, loss: 0.7442014813423157\n",
      "TRAINING: epoch31, iter600, loss: 0.7603570818901062\n",
      "TRAINING: epoch31, iter700, loss: 0.852615237236023\n",
      "TRAINING: epoch31, iter800, loss: 0.8072794675827026\n",
      "TRAINING: epoch31, iter900, loss: 0.6961835622787476\n",
      "TRAINING: epoch31, iter1000, loss: 0.8146098256111145\n",
      "TRAINING: epoch31, iter1100, loss: 0.7616003751754761\n",
      "TRAINING: epoch31, iter1200, loss: 0.816639244556427\n",
      "TRAINING: epoch31, iter1300, loss: 0.8810486197471619\n",
      "Finish epoch 31, time elapsed 186.01981329917908\n",
      "VALIDATION: iter0, loss: 0.753921627998352\n",
      "VALIDATION: iter100, loss: 0.6875292062759399\n",
      "VALIDATION: iter200, loss: 0.7419832944869995\n",
      "VALIDATION: iter300, loss: 0.7448287010192871\n",
      "Validation epoch 31: avg_iou = 0.5865747411749256, avg_acc = 0.7312943261061142\n",
      "Epoch: 32\n",
      "TRAINING: epoch32, iter0, loss: 0.7496106028556824\n",
      "TRAINING: epoch32, iter100, loss: 0.8625680804252625\n",
      "TRAINING: epoch32, iter200, loss: 0.7102353572845459\n",
      "TRAINING: epoch32, iter300, loss: 0.7620899677276611\n",
      "TRAINING: epoch32, iter400, loss: 0.8396527767181396\n",
      "TRAINING: epoch32, iter500, loss: 0.6778552532196045\n",
      "TRAINING: epoch32, iter600, loss: 0.701943039894104\n",
      "TRAINING: epoch32, iter700, loss: 0.8247810006141663\n",
      "TRAINING: epoch32, iter800, loss: 0.7768257260322571\n",
      "TRAINING: epoch32, iter900, loss: 0.8026315569877625\n",
      "TRAINING: epoch32, iter1000, loss: 0.7552087306976318\n",
      "TRAINING: epoch32, iter1100, loss: 0.769692063331604\n",
      "TRAINING: epoch32, iter1200, loss: 0.7692719101905823\n",
      "TRAINING: epoch32, iter1300, loss: 0.7284560203552246\n",
      "Finish epoch 32, time elapsed 188.8673334121704\n",
      "VALIDATION: iter0, loss: 0.7535938620567322\n",
      "VALIDATION: iter100, loss: 0.7353758811950684\n",
      "VALIDATION: iter200, loss: 0.6844332218170166\n",
      "VALIDATION: iter300, loss: 0.711284875869751\n",
      "Validation epoch 32: avg_iou = 0.58561703500463, avg_acc = 0.7312136970349212\n",
      "Epoch: 33\n",
      "TRAINING: epoch33, iter0, loss: 0.7952340841293335\n",
      "TRAINING: epoch33, iter100, loss: 0.8235912919044495\n",
      "TRAINING: epoch33, iter200, loss: 0.7817045450210571\n",
      "TRAINING: epoch33, iter300, loss: 0.8248919248580933\n",
      "TRAINING: epoch33, iter400, loss: 0.6625301837921143\n",
      "TRAINING: epoch33, iter500, loss: 0.7830991744995117\n",
      "TRAINING: epoch33, iter600, loss: 0.8528525829315186\n",
      "TRAINING: epoch33, iter700, loss: 0.8207119703292847\n",
      "TRAINING: epoch33, iter800, loss: 0.7866459488868713\n",
      "TRAINING: epoch33, iter900, loss: 0.8368268013000488\n",
      "TRAINING: epoch33, iter1000, loss: 0.6679587364196777\n",
      "TRAINING: epoch33, iter1100, loss: 0.8411434888839722\n",
      "TRAINING: epoch33, iter1200, loss: 0.7979284524917603\n",
      "TRAINING: epoch33, iter1300, loss: 0.8467133045196533\n",
      "Finish epoch 33, time elapsed 188.46869468688965\n",
      "VALIDATION: iter0, loss: 0.7136244773864746\n",
      "VALIDATION: iter100, loss: 0.7243914604187012\n",
      "VALIDATION: iter200, loss: 0.7173200845718384\n",
      "VALIDATION: iter300, loss: 0.7300037145614624\n",
      "Validation epoch 33: avg_iou = 0.5788143722868677, avg_acc = 0.7259192835039168\n",
      "Epoch: 34\n",
      "TRAINING: epoch34, iter0, loss: 0.7623194456100464\n",
      "TRAINING: epoch34, iter100, loss: 0.7924814224243164\n",
      "TRAINING: epoch34, iter200, loss: 0.9007854461669922\n",
      "TRAINING: epoch34, iter300, loss: 0.9115738272666931\n",
      "TRAINING: epoch34, iter400, loss: 0.7369463443756104\n",
      "TRAINING: epoch34, iter500, loss: 0.6771042943000793\n",
      "TRAINING: epoch34, iter600, loss: 0.7865912914276123\n",
      "TRAINING: epoch34, iter700, loss: 0.7877385020256042\n",
      "TRAINING: epoch34, iter800, loss: 0.8469133377075195\n",
      "TRAINING: epoch34, iter900, loss: 0.6969140768051147\n",
      "TRAINING: epoch34, iter1000, loss: 0.852314293384552\n",
      "TRAINING: epoch34, iter1100, loss: 0.8502697348594666\n",
      "TRAINING: epoch34, iter1200, loss: 0.7540988922119141\n",
      "TRAINING: epoch34, iter1300, loss: 0.8616525530815125\n",
      "Finish epoch 34, time elapsed 188.13187074661255\n",
      "VALIDATION: iter0, loss: 0.7446239590644836\n",
      "VALIDATION: iter100, loss: 0.700023353099823\n",
      "VALIDATION: iter200, loss: 0.6888517737388611\n",
      "VALIDATION: iter300, loss: 0.701380729675293\n",
      "Validation epoch 34: avg_iou = 0.5799148713474843, avg_acc = 0.7269935707547771\n",
      "Epoch: 35\n",
      "TRAINING: epoch35, iter0, loss: 0.8255806565284729\n",
      "TRAINING: epoch35, iter100, loss: 0.7932485938072205\n",
      "TRAINING: epoch35, iter200, loss: 0.753213107585907\n",
      "TRAINING: epoch35, iter300, loss: 0.7010583877563477\n",
      "TRAINING: epoch35, iter400, loss: 0.8050121068954468\n",
      "TRAINING: epoch35, iter500, loss: 0.6720386743545532\n",
      "TRAINING: epoch35, iter600, loss: 0.7459316849708557\n",
      "TRAINING: epoch35, iter700, loss: 0.7689751386642456\n",
      "TRAINING: epoch35, iter800, loss: 0.6638458967208862\n",
      "TRAINING: epoch35, iter900, loss: 0.8001872897148132\n",
      "TRAINING: epoch35, iter1000, loss: 0.9139715433120728\n",
      "TRAINING: epoch35, iter1100, loss: 0.8016279339790344\n",
      "TRAINING: epoch35, iter1200, loss: 0.8622082471847534\n",
      "TRAINING: epoch35, iter1300, loss: 0.8678033351898193\n",
      "Finish epoch 35, time elapsed 187.19384026527405\n",
      "VALIDATION: iter0, loss: 0.722619891166687\n",
      "VALIDATION: iter100, loss: 0.7287224531173706\n",
      "VALIDATION: iter200, loss: 0.6790808439254761\n",
      "VALIDATION: iter300, loss: 0.7035914659500122\n",
      "Validation epoch 35: avg_iou = 0.5881722887060535, avg_acc = 0.7324321442575598\n",
      "Epoch: 36\n",
      "TRAINING: epoch36, iter0, loss: 0.7598870396614075\n",
      "TRAINING: epoch36, iter100, loss: 0.7494996786117554\n",
      "TRAINING: epoch36, iter200, loss: 0.7518398761749268\n",
      "TRAINING: epoch36, iter300, loss: 0.8273998498916626\n",
      "TRAINING: epoch36, iter400, loss: 0.7203986644744873\n",
      "TRAINING: epoch36, iter500, loss: 0.8796989321708679\n",
      "TRAINING: epoch36, iter600, loss: 0.8015707731246948\n",
      "TRAINING: epoch36, iter700, loss: 0.7199546694755554\n",
      "TRAINING: epoch36, iter800, loss: 0.7831525802612305\n",
      "TRAINING: epoch36, iter900, loss: 0.7738943099975586\n",
      "TRAINING: epoch36, iter1000, loss: 0.8356047868728638\n",
      "TRAINING: epoch36, iter1100, loss: 0.8239389657974243\n",
      "TRAINING: epoch36, iter1200, loss: 0.7839874029159546\n",
      "TRAINING: epoch36, iter1300, loss: 0.835429847240448\n",
      "Finish epoch 36, time elapsed 187.7354278564453\n",
      "VALIDATION: iter0, loss: 0.7106189727783203\n",
      "VALIDATION: iter100, loss: 0.7072594165802002\n",
      "VALIDATION: iter200, loss: 0.738616943359375\n",
      "VALIDATION: iter300, loss: 0.7144284248352051\n",
      "Validation epoch 36: avg_iou = 0.5880122975626988, avg_acc = 0.7324299392415516\n",
      "Epoch: 37\n",
      "TRAINING: epoch37, iter0, loss: 0.7234070301055908\n",
      "TRAINING: epoch37, iter100, loss: 0.839326024055481\n",
      "TRAINING: epoch37, iter200, loss: 0.7660343647003174\n",
      "TRAINING: epoch37, iter300, loss: 0.7650455236434937\n",
      "TRAINING: epoch37, iter400, loss: 0.9033095240592957\n",
      "TRAINING: epoch37, iter500, loss: 0.9239175319671631\n",
      "TRAINING: epoch37, iter600, loss: 0.7921046018600464\n",
      "TRAINING: epoch37, iter700, loss: 0.8726248145103455\n",
      "TRAINING: epoch37, iter800, loss: 0.8731319308280945\n",
      "TRAINING: epoch37, iter900, loss: 0.8023126125335693\n",
      "TRAINING: epoch37, iter1000, loss: 0.767356276512146\n",
      "TRAINING: epoch37, iter1100, loss: 0.8336300253868103\n",
      "TRAINING: epoch37, iter1200, loss: 0.7777673006057739\n",
      "TRAINING: epoch37, iter1300, loss: 0.8029308319091797\n",
      "Finish epoch 37, time elapsed 185.41772651672363\n",
      "VALIDATION: iter0, loss: 0.7383365631103516\n",
      "VALIDATION: iter100, loss: 0.7617652416229248\n",
      "VALIDATION: iter200, loss: 0.6823723316192627\n",
      "VALIDATION: iter300, loss: 0.7411230802536011\n",
      "Validation epoch 37: avg_iou = 0.5769608194258675, avg_acc = 0.7240827699205769\n",
      "Epoch: 38\n",
      "TRAINING: epoch38, iter0, loss: 0.7412744760513306\n",
      "TRAINING: epoch38, iter100, loss: 0.7759878039360046\n",
      "TRAINING: epoch38, iter200, loss: 0.7011013031005859\n",
      "TRAINING: epoch38, iter300, loss: 0.7735484838485718\n",
      "TRAINING: epoch38, iter400, loss: 0.8456692695617676\n",
      "TRAINING: epoch38, iter500, loss: 0.7745640277862549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch38, iter600, loss: 0.8432649374008179\n",
      "TRAINING: epoch38, iter700, loss: 0.828835129737854\n",
      "TRAINING: epoch38, iter800, loss: 0.7495182156562805\n",
      "TRAINING: epoch38, iter900, loss: 0.6749385595321655\n",
      "TRAINING: epoch38, iter1000, loss: 0.6933484077453613\n",
      "TRAINING: epoch38, iter1100, loss: 0.7640780210494995\n",
      "TRAINING: epoch38, iter1200, loss: 0.7384985089302063\n",
      "TRAINING: epoch38, iter1300, loss: 0.6672236919403076\n",
      "Finish epoch 38, time elapsed 186.55152797698975\n",
      "VALIDATION: iter0, loss: 0.7291314601898193\n",
      "VALIDATION: iter100, loss: 0.7055260539054871\n",
      "VALIDATION: iter200, loss: 0.7203207015991211\n",
      "VALIDATION: iter300, loss: 0.714377760887146\n",
      "Validation epoch 38: avg_iou = 0.5876132026537141, avg_acc = 0.7320978298116086\n",
      "Epoch: 39\n",
      "TRAINING: epoch39, iter0, loss: 0.8282931447029114\n",
      "TRAINING: epoch39, iter100, loss: 0.7353931665420532\n",
      "TRAINING: epoch39, iter200, loss: 0.7887099385261536\n",
      "TRAINING: epoch39, iter300, loss: 0.7624936103820801\n",
      "TRAINING: epoch39, iter400, loss: 0.7555125951766968\n",
      "TRAINING: epoch39, iter500, loss: 0.8279433250427246\n",
      "TRAINING: epoch39, iter600, loss: 0.7740498185157776\n",
      "TRAINING: epoch39, iter700, loss: 0.7589848041534424\n",
      "TRAINING: epoch39, iter800, loss: 0.7082005739212036\n",
      "TRAINING: epoch39, iter900, loss: 0.7858554720878601\n",
      "TRAINING: epoch39, iter1000, loss: 0.826760470867157\n",
      "TRAINING: epoch39, iter1100, loss: 0.7801553010940552\n",
      "TRAINING: epoch39, iter1200, loss: 0.8518257141113281\n",
      "TRAINING: epoch39, iter1300, loss: 0.8161965012550354\n",
      "Finish epoch 39, time elapsed 185.30163598060608\n",
      "VALIDATION: iter0, loss: 0.6969833374023438\n",
      "VALIDATION: iter100, loss: 0.7347427606582642\n",
      "VALIDATION: iter200, loss: 0.7553770542144775\n",
      "VALIDATION: iter300, loss: 0.7153562903404236\n",
      "Validation epoch 39: avg_iou = 0.5818465816440866, avg_acc = 0.7283118071840771\n",
      "Epoch: 40\n",
      "TRAINING: epoch40, iter0, loss: 0.7727317810058594\n",
      "TRAINING: epoch40, iter100, loss: 0.7700294852256775\n",
      "TRAINING: epoch40, iter200, loss: 0.8040854930877686\n",
      "TRAINING: epoch40, iter300, loss: 0.7547702789306641\n",
      "TRAINING: epoch40, iter400, loss: 0.8184986114501953\n",
      "TRAINING: epoch40, iter500, loss: 0.6799448132514954\n",
      "TRAINING: epoch40, iter600, loss: 0.679153561592102\n",
      "TRAINING: epoch40, iter700, loss: 0.8097951412200928\n",
      "TRAINING: epoch40, iter800, loss: 0.8674612045288086\n",
      "TRAINING: epoch40, iter900, loss: 0.8692495226860046\n",
      "TRAINING: epoch40, iter1000, loss: 0.815029501914978\n",
      "TRAINING: epoch40, iter1100, loss: 0.8210561871528625\n",
      "TRAINING: epoch40, iter1200, loss: 0.8567390441894531\n",
      "TRAINING: epoch40, iter1300, loss: 0.7238751649856567\n",
      "Finish epoch 40, time elapsed 187.7178611755371\n",
      "VALIDATION: iter0, loss: 0.7084897756576538\n",
      "VALIDATION: iter100, loss: 0.7133685350418091\n",
      "VALIDATION: iter200, loss: 0.7416954636573792\n",
      "VALIDATION: iter300, loss: 0.7028591632843018\n",
      "Validation epoch 40: avg_iou = 0.5803308530529934, avg_acc = 0.727063463339165\n",
      "Epoch: 41\n",
      "TRAINING: epoch41, iter0, loss: 0.7092212438583374\n",
      "TRAINING: epoch41, iter100, loss: 0.6886872053146362\n",
      "TRAINING: epoch41, iter200, loss: 0.7685683369636536\n",
      "TRAINING: epoch41, iter300, loss: 0.7688096761703491\n",
      "TRAINING: epoch41, iter400, loss: 0.8307502269744873\n",
      "TRAINING: epoch41, iter500, loss: 0.8440232276916504\n",
      "TRAINING: epoch41, iter600, loss: 0.8239243030548096\n",
      "TRAINING: epoch41, iter700, loss: 0.8165786266326904\n",
      "TRAINING: epoch41, iter800, loss: 0.6453864574432373\n",
      "TRAINING: epoch41, iter900, loss: 0.8955360054969788\n",
      "TRAINING: epoch41, iter1000, loss: 0.8549690246582031\n",
      "TRAINING: epoch41, iter1100, loss: 0.8970938920974731\n",
      "TRAINING: epoch41, iter1200, loss: 0.8585579991340637\n",
      "TRAINING: epoch41, iter1300, loss: 0.7178086042404175\n",
      "Finish epoch 41, time elapsed 190.90459942817688\n",
      "VALIDATION: iter0, loss: 0.7348200082778931\n",
      "VALIDATION: iter100, loss: 0.6743202209472656\n",
      "VALIDATION: iter200, loss: 0.7378637790679932\n",
      "VALIDATION: iter300, loss: 0.7171778678894043\n",
      "Validation epoch 41: avg_iou = 0.588660074169956, avg_acc = 0.7331931167574072\n",
      "Epoch: 42\n",
      "TRAINING: epoch42, iter0, loss: 0.7401329278945923\n",
      "TRAINING: epoch42, iter100, loss: 0.8363650441169739\n",
      "TRAINING: epoch42, iter200, loss: 0.8395885825157166\n",
      "TRAINING: epoch42, iter300, loss: 0.6444395184516907\n",
      "TRAINING: epoch42, iter400, loss: 0.7256282567977905\n",
      "TRAINING: epoch42, iter500, loss: 0.7432536482810974\n",
      "TRAINING: epoch42, iter600, loss: 0.7535443902015686\n",
      "TRAINING: epoch42, iter700, loss: 0.8218805193901062\n",
      "TRAINING: epoch42, iter800, loss: 0.7065433263778687\n",
      "TRAINING: epoch42, iter900, loss: 0.7768346071243286\n",
      "TRAINING: epoch42, iter1000, loss: 0.7524803876876831\n",
      "TRAINING: epoch42, iter1100, loss: 0.8452559113502502\n",
      "TRAINING: epoch42, iter1200, loss: 0.8237085342407227\n",
      "TRAINING: epoch42, iter1300, loss: 0.7310760021209717\n",
      "Finish epoch 42, time elapsed 185.54783725738525\n",
      "VALIDATION: iter0, loss: 0.6958569288253784\n",
      "VALIDATION: iter100, loss: 0.7570429444313049\n",
      "VALIDATION: iter200, loss: 0.6980047821998596\n",
      "VALIDATION: iter300, loss: 0.7039024829864502\n",
      "Validation epoch 42: avg_iou = 0.5892817874452961, avg_acc = 0.7337257121925923\n",
      "Epoch: 43\n",
      "TRAINING: epoch43, iter0, loss: 0.8969699740409851\n",
      "TRAINING: epoch43, iter100, loss: 0.7692850232124329\n",
      "TRAINING: epoch43, iter200, loss: 0.8142387270927429\n",
      "TRAINING: epoch43, iter300, loss: 0.8854155540466309\n",
      "TRAINING: epoch43, iter400, loss: 0.7427246570587158\n",
      "TRAINING: epoch43, iter500, loss: 0.7985958456993103\n",
      "TRAINING: epoch43, iter600, loss: 0.6938269138336182\n",
      "TRAINING: epoch43, iter700, loss: 0.8152961730957031\n",
      "TRAINING: epoch43, iter800, loss: 0.7883636355400085\n",
      "TRAINING: epoch43, iter900, loss: 0.8866695761680603\n",
      "TRAINING: epoch43, iter1000, loss: 0.771937370300293\n",
      "TRAINING: epoch43, iter1100, loss: 0.7834326028823853\n",
      "TRAINING: epoch43, iter1200, loss: 0.7121390700340271\n",
      "TRAINING: epoch43, iter1300, loss: 0.7264552712440491\n",
      "Finish epoch 43, time elapsed 186.80181121826172\n",
      "VALIDATION: iter0, loss: 0.7129654884338379\n",
      "VALIDATION: iter100, loss: 0.716029167175293\n",
      "VALIDATION: iter200, loss: 0.7169731855392456\n",
      "VALIDATION: iter300, loss: 0.6973100900650024\n",
      "Validation epoch 43: avg_iou = 0.5787275474462936, avg_acc = 0.7249511273939218\n",
      "Epoch: 44\n",
      "TRAINING: epoch44, iter0, loss: 0.7498641014099121\n",
      "TRAINING: epoch44, iter100, loss: 0.8191670775413513\n",
      "TRAINING: epoch44, iter200, loss: 0.8130282163619995\n",
      "TRAINING: epoch44, iter300, loss: 0.8011035919189453\n",
      "TRAINING: epoch44, iter400, loss: 0.8333839178085327\n",
      "TRAINING: epoch44, iter500, loss: 0.8538311719894409\n",
      "TRAINING: epoch44, iter600, loss: 0.7876051664352417\n",
      "TRAINING: epoch44, iter700, loss: 0.7952001094818115\n",
      "TRAINING: epoch44, iter800, loss: 0.8112046718597412\n",
      "TRAINING: epoch44, iter900, loss: 0.8943708539009094\n",
      "TRAINING: epoch44, iter1000, loss: 0.7708271741867065\n",
      "TRAINING: epoch44, iter1100, loss: 0.6501222848892212\n",
      "TRAINING: epoch44, iter1200, loss: 0.8174729347229004\n",
      "TRAINING: epoch44, iter1300, loss: 0.8062318563461304\n",
      "Finish epoch 44, time elapsed 186.88740038871765\n",
      "VALIDATION: iter0, loss: 0.7120718955993652\n",
      "VALIDATION: iter100, loss: 0.7299617528915405\n",
      "VALIDATION: iter200, loss: 0.7194904088973999\n",
      "VALIDATION: iter300, loss: 0.7095457315444946\n",
      "Validation epoch 44: avg_iou = 0.5905753423918539, avg_acc = 0.735126021370959\n",
      "Epoch: 45\n",
      "TRAINING: epoch45, iter0, loss: 0.8615264892578125\n",
      "TRAINING: epoch45, iter100, loss: 0.7857787013053894\n",
      "TRAINING: epoch45, iter200, loss: 0.7183270454406738\n",
      "TRAINING: epoch45, iter300, loss: 0.7303439974784851\n",
      "TRAINING: epoch45, iter400, loss: 0.8603225946426392\n",
      "TRAINING: epoch45, iter500, loss: 0.8608347177505493\n",
      "TRAINING: epoch45, iter600, loss: 0.7677841186523438\n",
      "TRAINING: epoch45, iter700, loss: 0.8316097855567932\n",
      "TRAINING: epoch45, iter800, loss: 0.8199711441993713\n",
      "TRAINING: epoch45, iter900, loss: 0.8317087888717651\n",
      "TRAINING: epoch45, iter1000, loss: 0.7236883640289307\n",
      "TRAINING: epoch45, iter1100, loss: 0.7030867338180542\n",
      "TRAINING: epoch45, iter1200, loss: 0.8039171695709229\n",
      "TRAINING: epoch45, iter1300, loss: 0.8150259852409363\n",
      "Finish epoch 45, time elapsed 191.35011434555054\n",
      "VALIDATION: iter0, loss: 0.7277591228485107\n",
      "VALIDATION: iter100, loss: 0.7184577584266663\n",
      "VALIDATION: iter200, loss: 0.7188432812690735\n",
      "VALIDATION: iter300, loss: 0.7095630764961243\n",
      "Validation epoch 45: avg_iou = 0.5939740135598538, avg_acc = 0.7376363136875096\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch46, iter0, loss: 0.8667374849319458\n",
      "TRAINING: epoch46, iter100, loss: 0.7607404589653015\n",
      "TRAINING: epoch46, iter200, loss: 0.7521743178367615\n",
      "TRAINING: epoch46, iter300, loss: 0.7848842144012451\n",
      "TRAINING: epoch46, iter400, loss: 0.8033156991004944\n",
      "TRAINING: epoch46, iter500, loss: 0.7086553573608398\n",
      "TRAINING: epoch46, iter600, loss: 0.8676935434341431\n",
      "TRAINING: epoch46, iter700, loss: 0.7097979784011841\n",
      "TRAINING: epoch46, iter800, loss: 0.7072446942329407\n",
      "TRAINING: epoch46, iter900, loss: 0.7246055603027344\n",
      "TRAINING: epoch46, iter1000, loss: 0.7498409748077393\n",
      "TRAINING: epoch46, iter1100, loss: 0.8640657663345337\n",
      "TRAINING: epoch46, iter1200, loss: 0.743801474571228\n",
      "TRAINING: epoch46, iter1300, loss: 0.8387736082077026\n",
      "Finish epoch 46, time elapsed 182.79475259780884\n",
      "VALIDATION: iter0, loss: 0.7257758378982544\n",
      "VALIDATION: iter100, loss: 0.6993297934532166\n",
      "VALIDATION: iter200, loss: 0.7785953283309937\n",
      "VALIDATION: iter300, loss: 0.7454910278320312\n",
      "Validation epoch 46: avg_iou = 0.5829043549388202, avg_acc = 0.7290437347853361\n",
      "Epoch: 47\n",
      "TRAINING: epoch47, iter0, loss: 0.7785724997520447\n",
      "TRAINING: epoch47, iter100, loss: 0.7663795351982117\n",
      "TRAINING: epoch47, iter200, loss: 0.8439271450042725\n",
      "TRAINING: epoch47, iter300, loss: 0.7272271513938904\n",
      "TRAINING: epoch47, iter400, loss: 0.8162492513656616\n",
      "TRAINING: epoch47, iter500, loss: 0.7231481075286865\n",
      "TRAINING: epoch47, iter600, loss: 0.7636436223983765\n",
      "TRAINING: epoch47, iter700, loss: 0.755255937576294\n",
      "TRAINING: epoch47, iter800, loss: 0.6423275470733643\n",
      "TRAINING: epoch47, iter900, loss: 0.8228760957717896\n",
      "TRAINING: epoch47, iter1000, loss: 0.8378783464431763\n",
      "TRAINING: epoch47, iter1100, loss: 0.8208696842193604\n",
      "TRAINING: epoch47, iter1200, loss: 0.8213278651237488\n",
      "TRAINING: epoch47, iter1300, loss: 0.7805920839309692\n",
      "Finish epoch 47, time elapsed 182.57233667373657\n",
      "VALIDATION: iter0, loss: 0.7245298624038696\n",
      "VALIDATION: iter100, loss: 0.7200412154197693\n",
      "VALIDATION: iter200, loss: 0.7116957902908325\n",
      "VALIDATION: iter300, loss: 0.7236619591712952\n",
      "Validation epoch 47: avg_iou = 0.586801550548468, avg_acc = 0.7320562092225943\n",
      "Epoch: 48\n",
      "TRAINING: epoch48, iter0, loss: 0.756166398525238\n",
      "TRAINING: epoch48, iter100, loss: 0.7098759412765503\n",
      "TRAINING: epoch48, iter200, loss: 0.7335953712463379\n",
      "TRAINING: epoch48, iter300, loss: 0.7011950016021729\n",
      "TRAINING: epoch48, iter400, loss: 0.8365874886512756\n",
      "TRAINING: epoch48, iter500, loss: 0.7772496342658997\n",
      "TRAINING: epoch48, iter600, loss: 0.8688534498214722\n",
      "TRAINING: epoch48, iter700, loss: 0.7815325856208801\n",
      "TRAINING: epoch48, iter800, loss: 0.7517650127410889\n",
      "TRAINING: epoch48, iter900, loss: 0.8481888175010681\n",
      "TRAINING: epoch48, iter1000, loss: 0.738409161567688\n",
      "TRAINING: epoch48, iter1100, loss: 0.7126476764678955\n",
      "TRAINING: epoch48, iter1200, loss: 0.892266035079956\n",
      "TRAINING: epoch48, iter1300, loss: 0.8914439678192139\n",
      "Finish epoch 48, time elapsed 188.99997520446777\n",
      "VALIDATION: iter0, loss: 0.679926872253418\n",
      "VALIDATION: iter100, loss: 0.7114176750183105\n",
      "VALIDATION: iter200, loss: 0.6873505711555481\n",
      "VALIDATION: iter300, loss: 0.7041140794754028\n",
      "Validation epoch 48: avg_iou = 0.5899898124274923, avg_acc = 0.7344972880918588\n",
      "Epoch: 49\n",
      "TRAINING: epoch49, iter0, loss: 0.8033045530319214\n",
      "TRAINING: epoch49, iter100, loss: 0.8339268565177917\n",
      "TRAINING: epoch49, iter200, loss: 0.7878183126449585\n",
      "TRAINING: epoch49, iter300, loss: 0.8590699434280396\n",
      "TRAINING: epoch49, iter400, loss: 0.8951829671859741\n",
      "TRAINING: epoch49, iter500, loss: 0.776781439781189\n",
      "TRAINING: epoch49, iter600, loss: 0.6168754696846008\n",
      "TRAINING: epoch49, iter700, loss: 0.8015915751457214\n",
      "TRAINING: epoch49, iter800, loss: 0.9294323325157166\n",
      "TRAINING: epoch49, iter900, loss: 0.7446537613868713\n",
      "TRAINING: epoch49, iter1000, loss: 0.8886553645133972\n",
      "TRAINING: epoch49, iter1100, loss: 0.8281181454658508\n",
      "TRAINING: epoch49, iter1200, loss: 0.8725236654281616\n",
      "TRAINING: epoch49, iter1300, loss: 0.8186675310134888\n",
      "Finish epoch 49, time elapsed 192.96514749526978\n",
      "VALIDATION: iter0, loss: 0.7447836399078369\n",
      "VALIDATION: iter100, loss: 0.7183399200439453\n",
      "VALIDATION: iter200, loss: 0.7094686031341553\n",
      "VALIDATION: iter300, loss: 0.7154886722564697\n",
      "Validation epoch 49: avg_iou = 0.5829270788093112, avg_acc = 0.7292477942224759\n",
      "Epoch: 50\n",
      "TRAINING: epoch50, iter0, loss: 0.7631986737251282\n",
      "TRAINING: epoch50, iter100, loss: 0.7362900376319885\n",
      "TRAINING: epoch50, iter200, loss: 0.6939090490341187\n",
      "TRAINING: epoch50, iter300, loss: 0.7975252866744995\n",
      "TRAINING: epoch50, iter400, loss: 0.8387537598609924\n",
      "TRAINING: epoch50, iter500, loss: 0.6950491070747375\n",
      "TRAINING: epoch50, iter600, loss: 0.701732337474823\n",
      "TRAINING: epoch50, iter700, loss: 0.7316453456878662\n",
      "TRAINING: epoch50, iter800, loss: 0.9170578718185425\n",
      "TRAINING: epoch50, iter900, loss: 0.6681404113769531\n",
      "TRAINING: epoch50, iter1000, loss: 0.6799412369728088\n",
      "TRAINING: epoch50, iter1100, loss: 0.8069170713424683\n",
      "TRAINING: epoch50, iter1200, loss: 0.728848934173584\n",
      "TRAINING: epoch50, iter1300, loss: 0.8769491910934448\n",
      "Finish epoch 50, time elapsed 192.54561710357666\n",
      "VALIDATION: iter0, loss: 0.7305564880371094\n",
      "VALIDATION: iter100, loss: 0.727339506149292\n",
      "VALIDATION: iter200, loss: 0.689539909362793\n",
      "VALIDATION: iter300, loss: 0.7125833630561829\n",
      "Validation epoch 50: avg_iou = 0.5772304241336993, avg_acc = 0.7243568514710041\n",
      "Epoch: 51\n",
      "TRAINING: epoch51, iter0, loss: 0.7537270784378052\n",
      "TRAINING: epoch51, iter100, loss: 0.7953600883483887\n",
      "TRAINING: epoch51, iter200, loss: 0.8383700847625732\n",
      "TRAINING: epoch51, iter300, loss: 0.874297559261322\n",
      "TRAINING: epoch51, iter400, loss: 0.777076005935669\n",
      "TRAINING: epoch51, iter500, loss: 0.8271669149398804\n",
      "TRAINING: epoch51, iter600, loss: 0.6765656471252441\n",
      "TRAINING: epoch51, iter700, loss: 0.8786129951477051\n",
      "TRAINING: epoch51, iter800, loss: 0.8730961084365845\n",
      "TRAINING: epoch51, iter900, loss: 0.8886386156082153\n",
      "TRAINING: epoch51, iter1000, loss: 0.7293884754180908\n",
      "TRAINING: epoch51, iter1100, loss: 0.8598437905311584\n",
      "TRAINING: epoch51, iter1200, loss: 0.7983380556106567\n",
      "TRAINING: epoch51, iter1300, loss: 0.7646268606185913\n",
      "Finish epoch 51, time elapsed 193.66470336914062\n",
      "VALIDATION: iter0, loss: 0.695548415184021\n",
      "VALIDATION: iter100, loss: 0.7060791850090027\n",
      "VALIDATION: iter200, loss: 0.7185050249099731\n",
      "VALIDATION: iter300, loss: 0.7319145202636719\n",
      "Validation epoch 51: avg_iou = 0.5908558292175407, avg_acc = 0.7355138077664731\n",
      "Epoch: 52\n",
      "TRAINING: epoch52, iter0, loss: 0.809310793876648\n",
      "TRAINING: epoch52, iter100, loss: 0.7486467957496643\n",
      "TRAINING: epoch52, iter200, loss: 0.7395368814468384\n",
      "TRAINING: epoch52, iter300, loss: 0.7326829433441162\n",
      "TRAINING: epoch52, iter400, loss: 0.6533349752426147\n",
      "TRAINING: epoch52, iter500, loss: 0.76515132188797\n",
      "TRAINING: epoch52, iter600, loss: 0.762855052947998\n",
      "TRAINING: epoch52, iter700, loss: 0.8527718782424927\n",
      "TRAINING: epoch52, iter800, loss: 0.8167717456817627\n",
      "TRAINING: epoch52, iter900, loss: 0.8682176470756531\n",
      "TRAINING: epoch52, iter1000, loss: 0.8327495455741882\n",
      "TRAINING: epoch52, iter1100, loss: 0.7203933000564575\n",
      "TRAINING: epoch52, iter1200, loss: 0.8012683391571045\n",
      "TRAINING: epoch52, iter1300, loss: 0.7231214642524719\n",
      "Finish epoch 52, time elapsed 194.34903502464294\n",
      "VALIDATION: iter0, loss: 0.6934608817100525\n",
      "VALIDATION: iter100, loss: 0.7084072828292847\n",
      "VALIDATION: iter200, loss: 0.7543067336082458\n",
      "VALIDATION: iter300, loss: 0.6894279718399048\n",
      "Validation epoch 52: avg_iou = 0.5878856866217371, avg_acc = 0.7330175244986121\n",
      "Epoch: 53\n",
      "TRAINING: epoch53, iter0, loss: 0.7723186016082764\n",
      "TRAINING: epoch53, iter100, loss: 0.8098610043525696\n",
      "TRAINING: epoch53, iter200, loss: 0.7312238812446594\n",
      "TRAINING: epoch53, iter300, loss: 0.8159114718437195\n",
      "TRAINING: epoch53, iter400, loss: 0.8495738506317139\n",
      "TRAINING: epoch53, iter500, loss: 0.8214917778968811\n",
      "TRAINING: epoch53, iter600, loss: 0.8036444187164307\n",
      "TRAINING: epoch53, iter700, loss: 0.8642734885215759\n",
      "TRAINING: epoch53, iter800, loss: 0.8391993641853333\n",
      "TRAINING: epoch53, iter900, loss: 0.8227101564407349\n",
      "TRAINING: epoch53, iter1000, loss: 0.7474902868270874\n",
      "TRAINING: epoch53, iter1100, loss: 0.8002837300300598\n",
      "TRAINING: epoch53, iter1200, loss: 0.8216893672943115\n",
      "TRAINING: epoch53, iter1300, loss: 0.7444578409194946\n",
      "Finish epoch 53, time elapsed 186.70033955574036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: iter0, loss: 0.7595614194869995\n",
      "VALIDATION: iter100, loss: 0.7332571744918823\n",
      "VALIDATION: iter200, loss: 0.6901067495346069\n",
      "VALIDATION: iter300, loss: 0.7258524894714355\n",
      "Validation epoch 53: avg_iou = 0.5822442501338561, avg_acc = 0.7285814119808709\n",
      "Epoch: 54\n",
      "TRAINING: epoch54, iter0, loss: 0.81880784034729\n",
      "TRAINING: epoch54, iter100, loss: 0.7274534702301025\n",
      "TRAINING: epoch54, iter200, loss: 0.7211501002311707\n",
      "TRAINING: epoch54, iter300, loss: 0.7855264544487\n",
      "TRAINING: epoch54, iter400, loss: 0.6719740033149719\n",
      "TRAINING: epoch54, iter500, loss: 0.7903516292572021\n",
      "TRAINING: epoch54, iter600, loss: 0.8343048691749573\n",
      "TRAINING: epoch54, iter700, loss: 0.8234668970108032\n",
      "TRAINING: epoch54, iter800, loss: 0.8041123747825623\n",
      "TRAINING: epoch54, iter900, loss: 0.7458117008209229\n",
      "TRAINING: epoch54, iter1000, loss: 0.8240511417388916\n",
      "TRAINING: epoch54, iter1100, loss: 0.6715980768203735\n",
      "TRAINING: epoch54, iter1200, loss: 0.7786308526992798\n",
      "TRAINING: epoch54, iter1300, loss: 0.7663519382476807\n",
      "Finish epoch 54, time elapsed 198.67801642417908\n",
      "VALIDATION: iter0, loss: 0.7198309898376465\n",
      "VALIDATION: iter100, loss: 0.7210144996643066\n",
      "VALIDATION: iter200, loss: 0.7145682573318481\n",
      "VALIDATION: iter300, loss: 0.7247400283813477\n",
      "Validation epoch 54: avg_iou = 0.587469715680649, avg_acc = 0.7328496498848075\n",
      "Epoch: 55\n",
      "TRAINING: epoch55, iter0, loss: 0.8091556429862976\n",
      "TRAINING: epoch55, iter100, loss: 0.8903231620788574\n",
      "TRAINING: epoch55, iter200, loss: 0.7663649320602417\n",
      "TRAINING: epoch55, iter300, loss: 0.7112292647361755\n",
      "TRAINING: epoch55, iter400, loss: 0.7935273051261902\n",
      "TRAINING: epoch55, iter500, loss: 0.7914395928382874\n",
      "TRAINING: epoch55, iter600, loss: 0.7472981810569763\n",
      "TRAINING: epoch55, iter700, loss: 0.8056841492652893\n",
      "TRAINING: epoch55, iter800, loss: 0.7874672412872314\n",
      "TRAINING: epoch55, iter900, loss: 0.7271376848220825\n",
      "TRAINING: epoch55, iter1000, loss: 0.7175095081329346\n",
      "TRAINING: epoch55, iter1100, loss: 0.8797683715820312\n",
      "TRAINING: epoch55, iter1200, loss: 0.8246545791625977\n",
      "TRAINING: epoch55, iter1300, loss: 0.8021172881126404\n",
      "Finish epoch 55, time elapsed 186.66025567054749\n",
      "VALIDATION: iter0, loss: 0.7277493476867676\n",
      "VALIDATION: iter100, loss: 0.716094970703125\n",
      "VALIDATION: iter200, loss: 0.7687620520591736\n",
      "VALIDATION: iter300, loss: 0.6836155652999878\n",
      "Validation epoch 55: avg_iou = 0.592722658168024, avg_acc = 0.7365645403292642\n",
      "Epoch: 56\n",
      "TRAINING: epoch56, iter0, loss: 0.7701917290687561\n",
      "TRAINING: epoch56, iter100, loss: 0.7545856833457947\n",
      "TRAINING: epoch56, iter200, loss: 0.8622967600822449\n",
      "TRAINING: epoch56, iter300, loss: 0.7757559418678284\n",
      "TRAINING: epoch56, iter400, loss: 0.7376012802124023\n",
      "TRAINING: epoch56, iter500, loss: 0.7293949127197266\n",
      "TRAINING: epoch56, iter600, loss: 0.7951124906539917\n",
      "TRAINING: epoch56, iter700, loss: 0.7230987548828125\n",
      "TRAINING: epoch56, iter800, loss: 0.8731775283813477\n",
      "TRAINING: epoch56, iter900, loss: 0.7601855993270874\n",
      "TRAINING: epoch56, iter1000, loss: 0.800615668296814\n",
      "TRAINING: epoch56, iter1100, loss: 0.8059158325195312\n",
      "TRAINING: epoch56, iter1200, loss: 0.7536006569862366\n",
      "TRAINING: epoch56, iter1300, loss: 0.7677593231201172\n",
      "Finish epoch 56, time elapsed 195.03735947608948\n",
      "VALIDATION: iter0, loss: 0.6988753080368042\n",
      "VALIDATION: iter100, loss: 0.7214345932006836\n",
      "VALIDATION: iter200, loss: 0.6901557445526123\n",
      "VALIDATION: iter300, loss: 0.6962066888809204\n",
      "Validation epoch 56: avg_iou = 0.5864708979627979, avg_acc = 0.7314265441538682\n",
      "Epoch: 57\n",
      "TRAINING: epoch57, iter0, loss: 0.6380892992019653\n",
      "TRAINING: epoch57, iter100, loss: 0.75328528881073\n",
      "TRAINING: epoch57, iter200, loss: 0.6696259379386902\n",
      "TRAINING: epoch57, iter300, loss: 0.8374456763267517\n",
      "TRAINING: epoch57, iter400, loss: 0.833228349685669\n",
      "TRAINING: epoch57, iter500, loss: 0.9016351103782654\n",
      "TRAINING: epoch57, iter600, loss: 0.8480449914932251\n",
      "TRAINING: epoch57, iter700, loss: 0.5525327920913696\n",
      "TRAINING: epoch57, iter800, loss: 0.8136109113693237\n",
      "TRAINING: epoch57, iter900, loss: 0.768782913684845\n",
      "TRAINING: epoch57, iter1000, loss: 0.9030311107635498\n",
      "TRAINING: epoch57, iter1100, loss: 0.8232929706573486\n",
      "TRAINING: epoch57, iter1200, loss: 0.7475050091743469\n",
      "TRAINING: epoch57, iter1300, loss: 0.8628480434417725\n",
      "Finish epoch 57, time elapsed 186.14944863319397\n",
      "VALIDATION: iter0, loss: 0.727671205997467\n",
      "VALIDATION: iter100, loss: 0.7205197811126709\n",
      "VALIDATION: iter200, loss: 0.6787401437759399\n",
      "VALIDATION: iter300, loss: 0.7237160205841064\n",
      "Validation epoch 57: avg_iou = 0.5868870795662723, avg_acc = 0.7322525246819453\n",
      "Epoch: 58\n",
      "TRAINING: epoch58, iter0, loss: 0.787074625492096\n",
      "TRAINING: epoch58, iter100, loss: 0.7804097533226013\n",
      "TRAINING: epoch58, iter200, loss: 0.7342871427536011\n",
      "TRAINING: epoch58, iter300, loss: 0.6774193048477173\n",
      "TRAINING: epoch58, iter400, loss: 0.7249017953872681\n",
      "TRAINING: epoch58, iter500, loss: 0.6204842329025269\n",
      "TRAINING: epoch58, iter600, loss: 0.7270474433898926\n",
      "TRAINING: epoch58, iter700, loss: 0.7677751183509827\n",
      "TRAINING: epoch58, iter800, loss: 0.8482946157455444\n",
      "TRAINING: epoch58, iter900, loss: 0.8646621108055115\n",
      "TRAINING: epoch58, iter1000, loss: 0.8491036891937256\n",
      "TRAINING: epoch58, iter1100, loss: 0.8703098893165588\n",
      "TRAINING: epoch58, iter1200, loss: 0.9071792364120483\n",
      "TRAINING: epoch58, iter1300, loss: 0.8337588906288147\n",
      "Finish epoch 58, time elapsed 191.6832525730133\n",
      "VALIDATION: iter0, loss: 0.7160384654998779\n",
      "VALIDATION: iter100, loss: 0.692322850227356\n",
      "VALIDATION: iter200, loss: 0.704059362411499\n",
      "VALIDATION: iter300, loss: 0.7294702529907227\n",
      "Validation epoch 58: avg_iou = 0.5892001584394654, avg_acc = 0.7335143500299596\n",
      "Epoch: 59\n",
      "TRAINING: epoch59, iter0, loss: 0.7906872034072876\n",
      "TRAINING: epoch59, iter100, loss: 0.8245800733566284\n",
      "TRAINING: epoch59, iter200, loss: 0.7334897518157959\n",
      "TRAINING: epoch59, iter300, loss: 0.8921418786048889\n",
      "TRAINING: epoch59, iter400, loss: 0.7276887893676758\n",
      "TRAINING: epoch59, iter500, loss: 0.787750244140625\n",
      "TRAINING: epoch59, iter600, loss: 0.823131263256073\n",
      "TRAINING: epoch59, iter700, loss: 0.7898122668266296\n",
      "TRAINING: epoch59, iter800, loss: 0.8256118297576904\n",
      "TRAINING: epoch59, iter900, loss: 0.7843683362007141\n",
      "TRAINING: epoch59, iter1000, loss: 0.8030027747154236\n",
      "TRAINING: epoch59, iter1100, loss: 0.7852743864059448\n",
      "TRAINING: epoch59, iter1200, loss: 0.7478942275047302\n",
      "TRAINING: epoch59, iter1300, loss: 0.7347023487091064\n",
      "Finish epoch 59, time elapsed 181.6286826133728\n",
      "VALIDATION: iter0, loss: 0.7023735046386719\n",
      "VALIDATION: iter100, loss: 0.6994624137878418\n",
      "VALIDATION: iter200, loss: 0.7231814861297607\n",
      "VALIDATION: iter300, loss: 0.6852037310600281\n",
      "Validation epoch 59: avg_iou = 0.5900614852335916, avg_acc = 0.7346581007117656\n",
      "Epoch: 60\n",
      "TRAINING: epoch60, iter0, loss: 0.7497426271438599\n",
      "TRAINING: epoch60, iter100, loss: 0.7829089164733887\n",
      "TRAINING: epoch60, iter200, loss: 0.8682864904403687\n",
      "TRAINING: epoch60, iter300, loss: 0.76875239610672\n",
      "TRAINING: epoch60, iter400, loss: 0.6765345335006714\n",
      "TRAINING: epoch60, iter500, loss: 0.7035424709320068\n",
      "TRAINING: epoch60, iter600, loss: 0.7634297609329224\n",
      "TRAINING: epoch60, iter700, loss: 0.7115129232406616\n",
      "TRAINING: epoch60, iter800, loss: 0.8511043787002563\n",
      "TRAINING: epoch60, iter900, loss: 0.8152572512626648\n",
      "TRAINING: epoch60, iter1000, loss: 0.7107966542243958\n",
      "TRAINING: epoch60, iter1100, loss: 0.7634466290473938\n",
      "TRAINING: epoch60, iter1200, loss: 0.8141183853149414\n",
      "TRAINING: epoch60, iter1300, loss: 0.833811342716217\n",
      "Finish epoch 60, time elapsed 183.01664876937866\n",
      "VALIDATION: iter0, loss: 0.7018300294876099\n",
      "VALIDATION: iter100, loss: 0.719377338886261\n",
      "VALIDATION: iter200, loss: 0.7106418013572693\n",
      "VALIDATION: iter300, loss: 0.7041981220245361\n",
      "Validation epoch 60: avg_iou = 0.5891961907272908, avg_acc = 0.733945620059967\n",
      "Epoch: 61\n",
      "TRAINING: epoch61, iter0, loss: 0.7260705232620239\n",
      "TRAINING: epoch61, iter100, loss: 0.7184151411056519\n",
      "TRAINING: epoch61, iter200, loss: 0.797733724117279\n",
      "TRAINING: epoch61, iter300, loss: 0.8667324781417847\n",
      "TRAINING: epoch61, iter400, loss: 0.8172380328178406\n",
      "TRAINING: epoch61, iter500, loss: 0.726599931716919\n",
      "TRAINING: epoch61, iter600, loss: 0.7985455393791199\n",
      "TRAINING: epoch61, iter700, loss: 0.7256002426147461\n",
      "TRAINING: epoch61, iter800, loss: 0.809105634689331\n",
      "TRAINING: epoch61, iter900, loss: 0.7861684560775757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch61, iter1000, loss: 0.8973119854927063\n",
      "TRAINING: epoch61, iter1100, loss: 0.7768974304199219\n",
      "TRAINING: epoch61, iter1200, loss: 0.8275607228279114\n",
      "TRAINING: epoch61, iter1300, loss: 0.8398513793945312\n",
      "Finish epoch 61, time elapsed 182.83379697799683\n",
      "VALIDATION: iter0, loss: 0.7387415766716003\n",
      "VALIDATION: iter100, loss: 0.6977871656417847\n",
      "VALIDATION: iter200, loss: 0.7102757692337036\n",
      "VALIDATION: iter300, loss: 0.6962155103683472\n",
      "Validation epoch 61: avg_iou = 0.5855546923715677, avg_acc = 0.7312753319740295\n",
      "Epoch: 62\n",
      "TRAINING: epoch62, iter0, loss: 0.8193269968032837\n",
      "TRAINING: epoch62, iter100, loss: 0.7294341325759888\n",
      "TRAINING: epoch62, iter200, loss: 0.798903226852417\n",
      "TRAINING: epoch62, iter300, loss: 0.8366808891296387\n",
      "TRAINING: epoch62, iter400, loss: 0.8227255344390869\n",
      "TRAINING: epoch62, iter500, loss: 0.8869683742523193\n",
      "TRAINING: epoch62, iter600, loss: 0.9219652414321899\n",
      "TRAINING: epoch62, iter700, loss: 0.8757526874542236\n",
      "TRAINING: epoch62, iter800, loss: 0.6884702444076538\n",
      "TRAINING: epoch62, iter900, loss: 0.7696830034255981\n",
      "TRAINING: epoch62, iter1000, loss: 0.6482354998588562\n",
      "TRAINING: epoch62, iter1100, loss: 0.856469988822937\n",
      "TRAINING: epoch62, iter1200, loss: 0.837886393070221\n",
      "TRAINING: epoch62, iter1300, loss: 0.7077503204345703\n",
      "Finish epoch 62, time elapsed 183.66098833084106\n",
      "VALIDATION: iter0, loss: 0.7250280380249023\n",
      "VALIDATION: iter100, loss: 0.7256934642791748\n",
      "VALIDATION: iter200, loss: 0.7362655401229858\n",
      "VALIDATION: iter300, loss: 0.7433279752731323\n",
      "Validation epoch 62: avg_iou = 0.587763904101813, avg_acc = 0.7332961781701045\n",
      "Epoch: 63\n",
      "TRAINING: epoch63, iter0, loss: 0.7610651850700378\n",
      "TRAINING: epoch63, iter100, loss: 0.8640573620796204\n",
      "TRAINING: epoch63, iter200, loss: 0.6890304088592529\n",
      "TRAINING: epoch63, iter300, loss: 0.8496053814888\n",
      "TRAINING: epoch63, iter400, loss: 0.866320788860321\n",
      "TRAINING: epoch63, iter500, loss: 0.6418453454971313\n",
      "TRAINING: epoch63, iter600, loss: 0.7029228210449219\n",
      "TRAINING: epoch63, iter700, loss: 0.7951877117156982\n",
      "TRAINING: epoch63, iter800, loss: 0.7121994495391846\n",
      "TRAINING: epoch63, iter900, loss: 0.767316997051239\n",
      "TRAINING: epoch63, iter1000, loss: 0.8787244558334351\n",
      "TRAINING: epoch63, iter1100, loss: 0.8057580590248108\n",
      "TRAINING: epoch63, iter1200, loss: 0.7902385592460632\n",
      "TRAINING: epoch63, iter1300, loss: 0.7747290134429932\n",
      "Finish epoch 63, time elapsed 183.2396981716156\n",
      "VALIDATION: iter0, loss: 0.7428891658782959\n",
      "VALIDATION: iter100, loss: 0.7134727239608765\n",
      "VALIDATION: iter200, loss: 0.7043266296386719\n",
      "VALIDATION: iter300, loss: 0.6883680820465088\n",
      "Validation epoch 63: avg_iou = 0.5931885391918581, avg_acc = 0.7369234113550898\n",
      "Epoch: 64\n",
      "TRAINING: epoch64, iter0, loss: 0.8070241808891296\n",
      "TRAINING: epoch64, iter100, loss: 0.6364063024520874\n",
      "TRAINING: epoch64, iter200, loss: 0.874068558216095\n",
      "TRAINING: epoch64, iter300, loss: 0.740636944770813\n",
      "TRAINING: epoch64, iter400, loss: 0.725794792175293\n",
      "TRAINING: epoch64, iter500, loss: 0.845931351184845\n",
      "TRAINING: epoch64, iter600, loss: 0.8990774154663086\n",
      "TRAINING: epoch64, iter700, loss: 0.7719358205795288\n",
      "TRAINING: epoch64, iter800, loss: 0.8769816160202026\n",
      "TRAINING: epoch64, iter900, loss: 0.7452810406684875\n",
      "TRAINING: epoch64, iter1000, loss: 0.6471762657165527\n",
      "TRAINING: epoch64, iter1100, loss: 0.7906126976013184\n",
      "TRAINING: epoch64, iter1200, loss: 0.8309592008590698\n",
      "TRAINING: epoch64, iter1300, loss: 0.8034780025482178\n",
      "Finish epoch 64, time elapsed 187.70801758766174\n",
      "VALIDATION: iter0, loss: 0.7229906320571899\n",
      "VALIDATION: iter100, loss: 0.7181704044342041\n",
      "VALIDATION: iter200, loss: 0.74821937084198\n",
      "VALIDATION: iter300, loss: 0.7501576542854309\n",
      "Validation epoch 64: avg_iou = 0.5845192277609412, avg_acc = 0.7306502256820451\n",
      "Epoch: 65\n",
      "TRAINING: epoch65, iter0, loss: 0.7842051982879639\n",
      "TRAINING: epoch65, iter100, loss: 0.7278398275375366\n",
      "TRAINING: epoch65, iter200, loss: 0.922882616519928\n",
      "TRAINING: epoch65, iter300, loss: 0.8412021994590759\n",
      "TRAINING: epoch65, iter400, loss: 0.8114849328994751\n",
      "TRAINING: epoch65, iter500, loss: 0.7441040277481079\n",
      "TRAINING: epoch65, iter600, loss: 0.7753245830535889\n",
      "TRAINING: epoch65, iter700, loss: 0.7633329033851624\n",
      "TRAINING: epoch65, iter800, loss: 0.7759178876876831\n",
      "TRAINING: epoch65, iter900, loss: 0.7741950750350952\n",
      "TRAINING: epoch65, iter1000, loss: 0.8773696422576904\n",
      "TRAINING: epoch65, iter1100, loss: 0.8601647019386292\n",
      "TRAINING: epoch65, iter1200, loss: 0.7068471908569336\n",
      "TRAINING: epoch65, iter1300, loss: 0.789219856262207\n",
      "Finish epoch 65, time elapsed 182.2121069431305\n",
      "VALIDATION: iter0, loss: 0.7251553535461426\n",
      "VALIDATION: iter100, loss: 0.7392953634262085\n",
      "VALIDATION: iter200, loss: 0.6858901977539062\n",
      "VALIDATION: iter300, loss: 0.6982672810554504\n",
      "Validation epoch 65: avg_iou = 0.5827998136406514, avg_acc = 0.7291898353775935\n",
      "Epoch: 66\n",
      "TRAINING: epoch66, iter0, loss: 0.8207759857177734\n",
      "TRAINING: epoch66, iter100, loss: 0.782103955745697\n",
      "TRAINING: epoch66, iter200, loss: 0.727716326713562\n",
      "TRAINING: epoch66, iter300, loss: 0.7947041392326355\n",
      "TRAINING: epoch66, iter400, loss: 0.7842200994491577\n",
      "TRAINING: epoch66, iter500, loss: 0.7913715839385986\n",
      "TRAINING: epoch66, iter600, loss: 0.885488748550415\n",
      "TRAINING: epoch66, iter700, loss: 0.7924083471298218\n",
      "TRAINING: epoch66, iter800, loss: 0.8672783374786377\n",
      "TRAINING: epoch66, iter900, loss: 0.7750775814056396\n",
      "TRAINING: epoch66, iter1000, loss: 0.7562488913536072\n",
      "TRAINING: epoch66, iter1100, loss: 0.7613248825073242\n",
      "TRAINING: epoch66, iter1200, loss: 0.6683331727981567\n",
      "TRAINING: epoch66, iter1300, loss: 0.7947030663490295\n",
      "Finish epoch 66, time elapsed 181.7903561592102\n",
      "VALIDATION: iter0, loss: 0.7172732949256897\n",
      "VALIDATION: iter100, loss: 0.6977776885032654\n",
      "VALIDATION: iter200, loss: 0.714206337928772\n",
      "VALIDATION: iter300, loss: 0.678874671459198\n",
      "Validation epoch 66: avg_iou = 0.5955525711401185, avg_acc = 0.7385581358155208\n",
      "Epoch: 67\n",
      "TRAINING: epoch67, iter0, loss: 0.7654531002044678\n",
      "TRAINING: epoch67, iter100, loss: 0.7484691143035889\n",
      "TRAINING: epoch67, iter200, loss: 0.740495502948761\n",
      "TRAINING: epoch67, iter300, loss: 0.9169244170188904\n",
      "TRAINING: epoch67, iter400, loss: 0.7808027267456055\n",
      "TRAINING: epoch67, iter500, loss: 0.7137327194213867\n",
      "TRAINING: epoch67, iter600, loss: 0.7736683487892151\n",
      "TRAINING: epoch67, iter700, loss: 0.882115364074707\n",
      "TRAINING: epoch67, iter800, loss: 0.7839053273200989\n",
      "TRAINING: epoch67, iter900, loss: 0.770240843296051\n",
      "TRAINING: epoch67, iter1000, loss: 0.8086514472961426\n",
      "TRAINING: epoch67, iter1100, loss: 0.784032940864563\n",
      "TRAINING: epoch67, iter1200, loss: 0.8309885859489441\n",
      "TRAINING: epoch67, iter1300, loss: 0.6948167681694031\n",
      "Finish epoch 67, time elapsed 180.1910264492035\n",
      "VALIDATION: iter0, loss: 0.7363475561141968\n",
      "VALIDATION: iter100, loss: 0.732039749622345\n",
      "VALIDATION: iter200, loss: 0.7157687544822693\n",
      "VALIDATION: iter300, loss: 0.7240500450134277\n",
      "Validation epoch 67: avg_iou = 0.5900566929311895, avg_acc = 0.7347820595129212\n",
      "Epoch: 68\n",
      "TRAINING: epoch68, iter0, loss: 0.7237285375595093\n",
      "TRAINING: epoch68, iter100, loss: 0.8055769205093384\n",
      "TRAINING: epoch68, iter200, loss: 0.7178562879562378\n",
      "TRAINING: epoch68, iter300, loss: 0.8235828876495361\n",
      "TRAINING: epoch68, iter400, loss: 0.8454813361167908\n",
      "TRAINING: epoch68, iter500, loss: 0.7594335675239563\n",
      "TRAINING: epoch68, iter600, loss: 0.6679635047912598\n",
      "TRAINING: epoch68, iter700, loss: 0.6928079724311829\n",
      "TRAINING: epoch68, iter800, loss: 0.7342731952667236\n",
      "TRAINING: epoch68, iter900, loss: 0.6736270189285278\n",
      "TRAINING: epoch68, iter1000, loss: 0.8250751495361328\n",
      "TRAINING: epoch68, iter1100, loss: 0.7728508710861206\n",
      "TRAINING: epoch68, iter1200, loss: 0.759497344493866\n",
      "TRAINING: epoch68, iter1300, loss: 0.77043616771698\n",
      "Finish epoch 68, time elapsed 188.52885055541992\n",
      "VALIDATION: iter0, loss: 0.714814305305481\n",
      "VALIDATION: iter100, loss: 0.7335615158081055\n",
      "VALIDATION: iter200, loss: 0.7230323553085327\n",
      "VALIDATION: iter300, loss: 0.7152674198150635\n",
      "Validation epoch 68: avg_iou = 0.5891295962369264, avg_acc = 0.7342629854358844\n",
      "Epoch: 69\n",
      "TRAINING: epoch69, iter0, loss: 0.8318804502487183\n",
      "TRAINING: epoch69, iter100, loss: 0.7622714638710022\n",
      "TRAINING: epoch69, iter200, loss: 0.8403096199035645\n",
      "TRAINING: epoch69, iter300, loss: 0.7893891334533691\n",
      "TRAINING: epoch69, iter400, loss: 0.6300803422927856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING: epoch69, iter500, loss: 0.7754766345024109\n",
      "TRAINING: epoch69, iter600, loss: 0.6727285385131836\n",
      "TRAINING: epoch69, iter700, loss: 0.900611162185669\n",
      "TRAINING: epoch69, iter800, loss: 0.7992609143257141\n",
      "TRAINING: epoch69, iter900, loss: 0.7350746989250183\n",
      "TRAINING: epoch69, iter1000, loss: 0.6012049913406372\n",
      "TRAINING: epoch69, iter1100, loss: 0.7384932041168213\n",
      "TRAINING: epoch69, iter1200, loss: 0.6954589486122131\n",
      "TRAINING: epoch69, iter1300, loss: 0.7520740628242493\n",
      "Finish epoch 69, time elapsed 180.24627590179443\n",
      "VALIDATION: iter0, loss: 0.7022507786750793\n"
     ]
    }
   ],
   "source": [
    "#val(0)  # show the accuracy before training\n",
    "#tranform - 0, mirror flip\n",
    "#transform - 1, rotate\n",
    "#transform - 2, resizedcrop\n",
    "train_loss, val_loss, val_inputs = train()\n",
    "#print(\"Input 0 : \",val_inputs[0])\n",
    "#print(\"Input 1 : \",val_inputs[1])\n",
    "#print(\"Input 0 shape:\",val_inputs[0].shape)\n",
    "#print(\"Input 1 shape:\",val_inputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
