{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader# For custom data-sets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "n_class = 27\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "    'name'        , \n",
    "    'level3Id'    , \n",
    "    'color'       , \n",
    "    ] )\n",
    "\n",
    "labels = [\n",
    "    #       name                     level3Id  color\n",
    "    Label(  'road'                 ,    0  , (128, 64,128)  ),\n",
    "    Label(  'drivable fallback'    ,    1  , ( 81,  0, 81)  ),\n",
    "    Label(  'sidewalk'             ,    2  , (244, 35,232)  ),\n",
    "    Label(  'non-drivable fallback',    3  , (152,251,152)  ),\n",
    "    Label(  'person/animal'        ,    4  , (220, 20, 60)  ),\n",
    "    Label(  'rider'                ,    5  , (255,  0,  0)  ),\n",
    "    Label(  'motorcycle'           ,    6  , (  0,  0,230)  ),\n",
    "    Label(  'bicycle'              ,   7  , (119, 11, 32)  ),\n",
    "    Label(  'autorickshaw'         ,   8  , (255, 204, 54) ),\n",
    "    Label(  'car'                  ,   9  , (  0,  0,142)  ),\n",
    "    Label(  'truck'                ,  10 ,  (  0,  0, 70)  ),\n",
    "    Label(  'bus'                  ,  11 ,  (  0, 60,100)  ),\n",
    "    Label(  'vehicle fallback'     ,  12 ,  (136, 143, 153)),  \n",
    "    Label(  'curb'                 ,   13 ,  (220, 190, 40)),\n",
    "    Label(  'wall'                 ,  14 ,  (102,102,156)  ),\n",
    "    Label(  'fence'                ,  15 ,  (190,153,153)  ),\n",
    "    Label(  'guard rail'           ,  16 ,  (180,165,180)  ),\n",
    "    Label(  'billboard'            ,   17 ,  (174, 64, 67) ),\n",
    "    Label(  'traffic sign'         ,  18 ,  (220,220,  0)  ),\n",
    "    Label(  'traffic light'        ,  19 ,  (250,170, 30)  ),\n",
    "    Label(  'pole'                 ,  20 ,  (153,153,153)  ),\n",
    "    Label(  'obs-str-bar-fallback' , 21 ,  (169, 187, 214) ),  \n",
    "    Label(  'building'             ,  22 ,  ( 70, 70, 70)  ),\n",
    "    Label(  'bridge/tunnel'        ,  23 ,  (150,100,100)  ),\n",
    "    Label(  'vegetation'           ,  24 ,  (107,142, 35)  ),\n",
    "    Label(  'sky'                  ,  25 ,  ( 70,130,180)  ),\n",
    "    Label(  'unlabeled'            ,  26 ,  (  0,  0,  0)  ),\n",
    "]   \n",
    "\n",
    "class IddDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, n_class=n_class, transforms_=None):\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.n_class   = n_class\n",
    "        self.mode = csv_file\n",
    "        \n",
    "        # Add any transformations here\n",
    "        \n",
    "        # The following transformation normalizes each channel using the mean and std provided\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.CenterCrop((720, 1280)),\n",
    "                                              transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = self.data.iloc[idx, 0]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        label_name = self.data.iloc[idx, 1]\n",
    "        label = Image.open(label_name)\n",
    "        \n",
    "        img = np.asarray(img) / 255. # scaling [0-255] values to [0-1]\n",
    "        label = np.asarray(label)\n",
    "        \n",
    "        img = self.transforms(img).float() # Normalization\n",
    "        label = torch.from_numpy(label.copy()).long() # convert to tensor\n",
    "\n",
    "        # create one-hot encoding\n",
    "        h, w = label.shape\n",
    "        target = torch.zeros(self.n_class, h, w)\n",
    "        for c in range(self.n_class):\n",
    "            target[c][label == c] = 1\n",
    "        \n",
    "        return img, target, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IddDataset(csv_file='train.csv')\n",
    "val_dataset = IddDataset(csv_file='val.csv')\n",
    "test_dataset = IddDataset(csv_file='test.csv')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 128, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 128, num_workers=0, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 128, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018\n",
      "2009\n",
      "1004\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getitem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-22305d246add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(train_dataset[0][0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Permute the object into a different shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.imshow(tensor_image.permute(1, 2, 0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#plt.imshow(test_image.permute(1, 2, 0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getitem' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print the shape of the training dataset\n",
    "# print(train_dataset[0][0].shape)\n",
    "# Permute the object into a different shape\n",
    "train_image = getitem(train_dataset, 0)\n",
    "#plt.imshow(tensor_image.permute(1, 2, 0))\n",
    "#plt.imshow(test_image.permute(1, 2, 0))\n",
    "#plt.imshow(val_image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of weight = torch.Size([32, 3, 3, 3])\n",
      "Dimension of bias = torch.Size([32])\n",
      "Dimension of weight = torch.Size([64, 32, 3, 3])\n",
      "Dimension of bias = torch.Size([64])\n",
      "Dimension of weight = torch.Size([128, 64, 3, 3])\n",
      "Dimension of bias = torch.Size([128])\n",
      "Dimension of weight = torch.Size([256, 128, 3, 3])\n",
      "Dimension of bias = torch.Size([256])\n",
      "Dimension of weight = torch.Size([512, 256, 3, 3])\n",
      "Dimension of bias = torch.Size([512])\n",
      "Dimension of weight = torch.Size([512, 512, 3, 3])\n",
      "Dimension of bias = torch.Size([512])\n",
      "Dimension of weight = torch.Size([512, 256, 3, 3])\n",
      "Dimension of bias = torch.Size([256])\n",
      "Dimension of weight = torch.Size([256, 128, 3, 3])\n",
      "Dimension of bias = torch.Size([128])\n",
      "Dimension of weight = torch.Size([128, 64, 3, 3])\n",
      "Dimension of bias = torch.Size([64])\n",
      "Dimension of weight = torch.Size([64, 32, 3, 3])\n",
      "Dimension of bias = torch.Size([32])\n",
      "Dimension of weight = torch.Size([27, 32, 1, 1])\n",
      "Dimension of bias = torch.Size([27])\n",
      "Reached train function\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "# First read the dataset\n",
    "train_dataset = IddDataset(csv_file='train.csv')\n",
    "val_dataset = IddDataset(csv_file='val.csv')\n",
    "test_dataset = IddDataset(csv_file='test.csv')\n",
    "\n",
    "# train_loader, val_loader and test_loader are three different sets of data\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 128, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 128, num_workers=0, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 128, num_workers=0, shuffle=False)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data)\n",
    "        print(\"Dimension of weight = {}\".format(m.weight.shape))\n",
    "        print(\"Dimension of bias = {}\".format(m.bias.shape))\n",
    "        #torch.nn.init.xavier_uniform(m.bias.data)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        \n",
    "epochs = 100        \n",
    "criterion = torch.nn.BCELoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "fcn_model = FCN(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(fcn_model.parameters(), lr=10**-4)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    fcn_model = fcn_model.cuda()\n",
    "\n",
    "        \n",
    "def train():\n",
    "    print(\"Reached train function\")\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        for itera, (X, tar, Y) in enumerate(train_loader):\n",
    "            print(\"Printing the contents of X, tar and Y\")\n",
    "            print(\"X, tar, Y are {}, {} and {}\".format(type(X), type(tar), type(Y)))\n",
    "            optimizer.zero_grad()\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()# Move your inputs onto the gpu\n",
    "                labels = Y.cuda()# Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, labels = X, Y# Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = fcn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, itera, loss.item()))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        torch.save(fcn_model, 'best_model')\n",
    "\n",
    "        val(epoch)\n",
    "        fcn_model.train()\n",
    "    \n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    fcn_model.eval() # Don't forget to put in eval mode !\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "def test():\n",
    "    fcn_model.eval()\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #val(0)  # show the accuracy before training\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
